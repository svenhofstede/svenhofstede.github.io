<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tags on Sven Hofstede</title><link>https://svenhofstede.com/tags/</link><description>Recent content in Tags on Sven Hofstede</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://svenhofstede.com/tags/index.xml" rel="self" type="application/rss+xml"/><item><title>Simplicity for the web</title><link>https://svenhofstede.com/simplicity-for-the-web/</link><pubDate>Tue, 18 Apr 2023 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/simplicity-for-the-web/</guid><description>&lt;p>Front-end engineering seems terrifying.&lt;/p>
&lt;p>The amount of different frontend frameworks and the speed in which stuff goes out of fashion. The need to write everything in Javascript which is in most cases a completely different language to your backend. The need to even make the distinction between a frontend and backend dev in the first place. Why has it gotten so far?!&lt;/p>
&lt;p>I&amp;rsquo;m a big fan of keeping the front-end of a web application simple. I&amp;rsquo;d argue that most web applications is development today don&amp;rsquo;t need to complex frontend app and would do just fine using server-side rendered templates. I&amp;rsquo;ve recently used &lt;a href="https://htmx.org/">htmx&lt;/a> together with FastAPI and the experience was great. I definitely had to learn a thing or two along the way but generally it was quite painless. Dynamically returning html snippets from the server just makes &lt;strong>so much sense&lt;/strong> in my head. Super complex frontends like large social media websites and big e-commerce websites might be good candidates for an entirely separate Javascript frontends but it&amp;rsquo;s major overkill for small crud applications and needlessly adds complexity.&lt;/p>
&lt;p>I think this is also fed by the existence of code bootcamps who attempt to get a candidate ready for the industry asap. They are taught a Javascript framework to build frontends because there is a lot of open positions in this area. But I don&amp;rsquo;t think these candidates are taught the downsides of this approach and of the existence of server-side rendered alternatives.&lt;/p>
&lt;p>I&amp;rsquo;m also a big fan of static site generators to serve content. It&amp;rsquo;s lightning fast, costs practically nothing to host and is super safe as no one can comprise the backend.&lt;/p></description></item><item><title>Show Your Work</title><link>https://svenhofstede.com/show-your-work/</link><pubDate>Tue, 28 Sep 2021 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/show-your-work/</guid><description>&lt;p>&lt;em>Written by Austin Kleon&lt;/em>&lt;/p>
&lt;p>I&amp;rsquo;m very much an introvert. I have a difficulty &amp;lsquo;marketing&amp;rsquo; myself by showing my work.&lt;/p>
&lt;p>This book gives a very concise introduction on the need for showing your work and also some concrete tips on how to do it. After reading it I 100% agree with the message.&lt;/p>
&lt;p>Focus on documenting instead of creating perfect content. Document your process of learning and write out your thought process. It stresses the need for a personal webspace that is owned solely by you. Embrace being an amateur and find that curiosity back.&lt;/p>
&lt;p>I finished this book in one evening which is extremely quick. The book reads super fast and is also very short in terms of actual text. The books contains a lot of graphics and full page images. I don&amp;rsquo;t think this book is worth the sticker price and the entire book could have been an extended blog post.&lt;/p>
&lt;p>I&amp;rsquo;d say: &lt;strong>Read it&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/book_reviews/show_your_work.jpeg" alt="cover">&lt;/p></description></item><item><title>Weapon of Math Destruction</title><link>https://svenhofstede.com/weapon-of-math-destruction/</link><pubDate>Sun, 19 Feb 2017 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/weapon-of-math-destruction/</guid><description>&lt;p>&lt;em>Written by Cathy O’Neil&lt;/em>&lt;/p>
&lt;p>Machine Learning and other mathematical algorithms are more and move taking over decision making. Whether someone is given a loan or an insurance policy. If someone gets fired because of not achieving the required efficiency based on the algorithm&amp;rsquo;s requirements or if someone gets the job in the first place. If someone might continue to commit crimes if we keep them on the street. If someone is showered with expensive, for-profit college advertisements or other high-interest, predatory loans. The decisions these models make are considered objectives and not negotiable. However, they are at a severe risk of a nasty feedback loop.&lt;/p>
&lt;p>In this book, Cathy describes many cases of this happening in the world right now. She has witnessed first hand how models are being given too much power and how not enough energy or thought is being invested into designing and developing &amp;lsquo;unbiased&amp;rsquo; models.&lt;/p>
&lt;p>The book does have a clear tendency towards the negative consequences of machine learning models. Little to no attention is given to the positive and innovative use cases that have come from these models. The books also feels a little long by the sheer number of cases she brings up. After the 10th case of biased models the message has gotten through clear enough and adding additional examples felt a little redundant.&lt;/p>
&lt;p>I&amp;rsquo;d say: &lt;strong>Read it&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/book_reviews/weapon_math.jpeg" alt="cover">&lt;/p></description></item><item><title>What I’m struggling with as a self-learner</title><link>https://svenhofstede.com/what-im-struggling-with-as-a-self-learner/</link><pubDate>Sun, 22 Jan 2017 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/what-im-struggling-with-as-a-self-learner/</guid><description>&lt;p>Pretty soon I will be starting a new job where I will be working as a Java developer. I have some professional experience writing Scala code (Spark) but this was in a different context. Moving data around is very different to application development. I&amp;rsquo;m therefore spending a couple hours each week brushing up on my programming skills and I thought it would be interesting to document the struggles I&amp;rsquo;m currently facing.&lt;/p>
&lt;h3 id="recognizing-when-to-use-a-design-pattern">Recognizing when to use a design pattern&lt;/h3>
&lt;p>I&amp;rsquo;m still struggling to recognize when to implement design patterns. Main reason is probably because I don&amp;rsquo;t know what they do yet :) I need to find some good resources that give a good overview of the patterns and when/how to implement them. Head First Design Patterns is on my reading list but will first need to purchase. There probably are some good resources online so I&amp;rsquo;ll start my search there.&lt;/p>
&lt;h3 id="finding-fun-projects-to-work-on">Finding fun projects to work on&lt;/h3>
&lt;p>After learning the basics using online courses it&amp;rsquo;s best to find a cool projects that you can work on. This works even better if you&amp;rsquo;re developing something that you actually need. I however can&amp;rsquo;t come up with any interesting projects that I personally have a use for.&lt;/p>
&lt;p>I have &amp;lsquo;resorted&amp;rsquo; to create a simple game using the PyGame library. It&amp;rsquo;s more of simulation game simulating a taxi company. This combines many aspects of programming that I would like to learn. Mostly TDD and object-oriented programming&lt;/p>
&lt;h3 id="doing-the-work">Doing the work&lt;/h3>
&lt;p>As with all learning activities that requires deliberate effort, it&amp;rsquo;s hard to get started! After coming home from work it&amp;rsquo;s tough to get yourself started.&lt;/p></description></item><item><title>My News Diet</title><link>https://svenhofstede.com/my-news-diet/</link><pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/my-news-diet/</guid><description>&lt;p>I actively try to avoid any type of news/media. I have de-activated my Facebook account. I don&amp;rsquo;t read newspapers or magazines.&lt;/p>
&lt;h2 id="total-connectivity">Total connectivity&lt;/h2>
&lt;p>My friend was in New Zealand a couple of months back. This is quite literally the other side of the world to where I live. While he was there an severe earthquake struck the island. According to him, he was reading about the earthquake on belgian news sites &lt;strong>10 minutes&lt;/strong> after it happened.&lt;/p>
&lt;p>In this day and age we can follow everything that happens in the world by unlocking our smartphones. Before the existence of internet and total connectivity bad (and good) things happened as well but people far away just wouldn&amp;rsquo;t know about it. If the earthquake would of happened 300 years ago then only a very small percentage of people in the world would know and therefore worry about it.&lt;/p>
&lt;h2 id="living-in-fear">Living in fear&lt;/h2>
&lt;p>Because of this bombardment of mostly negative news it seems most people think we live in a world full of terror and misery. I think I remember reading somewhere that we currently live in the safest period the human world has ever seen.&lt;/p>
&lt;p>The latest development related to ISIS and terrorism is especially insiduous. People are staying away from public gatherings and leaning on the safe side. But casualties of terrorist attacks, however tragic, are only an extremely small minority. What is, statistically speaking, the chance that you will be in such a situation?&lt;/p>
&lt;p>The media is infesting people&amp;rsquo;s minds with worst-case scenarios. It&amp;rsquo;s negativity overload.&lt;/p>
&lt;h2 id="my-contribution-or-lack-thereof">My contribution, or lack thereof&lt;/h2>
&lt;p>The majority of world events have zero affect on the course of my life and the lives of billions of others. Does my knowing of the event of the earthquake have any effect, let alone a positive one, on anyone? Probably not. This ties back nicely to the stoic idea of not worrying about things you can&amp;rsquo;t control.&lt;/p>
&lt;p>And even though I try to avoid it, news always finds a way to slip through the net. You might hear a small snippet of news on the radio or your colleagues are discussing recent events right next to you. If something is THAT important, it will arrive at your conscious soon enough. No need to go looking for it.&lt;/p>
&lt;h2 id="shit-happens">Shit happens&lt;/h2>
&lt;p>To be clear I&amp;rsquo;m not saying that I don&amp;rsquo;t feel bad when bad things happen because I do. Hearing about negative news has a negative affect on me. Catastrophies can have major effects on the people involved and I don&amp;rsquo;t wish that to anyone. I&amp;rsquo;m saying that I will avoid feeling bad if I can, especially if neither I or anyone else have anything to gain by me feeling bad.&lt;/p>
&lt;p>I will admit that it&amp;rsquo;s an easy stance to take. I probably can&amp;rsquo;t help anyone so let me just ignore all of it. But every second spent pondering without action from my side is a second wasted and might cripple my happiness.&lt;/p></description></item><item><title>Things I should learn as a new programmer</title><link>https://svenhofstede.com/things-i-should-learn-as-a-new-programmer/</link><pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/things-i-should-learn-as-a-new-programmer/</guid><description>&lt;h3 id="algorithms--data-structures">Algorithms &amp;amp; Data Structures&lt;/h3>
&lt;p>There are literally limitless ways to solve any given problem. A good programmer will know the right tool for the job by using existing Algorithms and Data Structures.&lt;/p>
&lt;p>I think it&amp;rsquo;s also a good idea to have the basic intuition of how well known algorithms work. For example, know how the various sorting algorithms are implemented. This will highlight good algorithn design.&lt;/p>
&lt;p>I also plan to eventually finish the Algorithms course on Coursera starting &lt;a href="https://www.coursera.org/learn/algorithms-divide-conquer">here.&lt;/a>&lt;/p>
&lt;h3 id="design-patterns">Design Patterns&lt;/h3>
&lt;p>This is very similar to the previous point. I need to learn to identify situation where I can use an existing Design Patterns.&lt;/p>
&lt;p>&lt;a href="https://www.amazon.com/Head-First-Design-Patterns-Brain-Friendly/dp/0596007124">Head First Design Patterns&lt;/a> is on my reading list. I think this will give me a good base to start learning about Design Patterns on the job.&lt;/p>
&lt;h3 id="test-driven-development">Test Driven Development&lt;/h3>
&lt;p>The concepts of TDD make much sense to me and I believe that it&amp;rsquo;s critical if you want to end up with maintainable code. I don&amp;rsquo;t think it&amp;rsquo;s makes development &amp;rsquo;easier&amp;rsquo; as you need to think about and write tests. It also forces you to deal with all edge cases in your code which is only a good thing.&lt;/p>
&lt;p>Becoming comfortable with the TDD workflow will be my first priority.&lt;/p>
&lt;h3 id="writing-clean-code">Writing clean code&lt;/h3>
&lt;p>Beginner&amp;rsquo;s code is not pretty. I&amp;rsquo;m hoping to write some proper clean code as soon as possible. Not enough attention is spent on this subject in courses or schools.&lt;/p>
&lt;h3 id="java--python">Java &amp;amp; Python&lt;/h3>
&lt;p>I want to be proficient at both Java &amp;amp; Python. That way I have nice balance between dynamic and statically typed. These language also see two difference usages in the workplace and they both still have a bright future ahead of them.&lt;/p>
&lt;p>In developing for the web I&amp;rsquo;ll also pick up some Javascript.&lt;/p></description></item><item><title>Outwitting the Devil</title><link>https://svenhofstede.com/outwitting-the-devil/</link><pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/outwitting-the-devil/</guid><description>&lt;p>&lt;em>Written by Napoleon Hill&lt;/em>&lt;/p>
&lt;p>What would it be like to interview the devil? Well, turns out it&amp;rsquo;s extremely educational.&lt;/p>
&lt;p>In this book Napoleon Hill first gives a rundown of the early life of Napoleon Hill and the problems he encounters. The second part is an interview, or rather a confession, with the devil. The interview part is the core of the book and the reason you should read it. During the interview the devil is obliged to give full, detailed and uncensored explanation of how he is brainwashing people into becoming drifters.&lt;/p>
&lt;p>Drifters are people who move through life without purpose. They procrastinate. They are easily influenced. They prefer to &lt;em>consume&lt;/em> instead of &lt;em>create&lt;/em>. They are peons that the devil uses to spread the disease of drifting to other people by promoting mediocrity. Laziness + Indifference = Drifting. Fortunately the devil also explains in great detail how to prevent drifting.&lt;/p>
&lt;p>&lt;strong>Definiteness of purposes&lt;/strong> applied over &lt;strong>time&lt;/strong>, thereby calling forth &lt;strong>hypnotic rhythm&lt;/strong> in your favor, prevents drifting.&lt;/p>
&lt;p>Of course the use of the devil character and interview format is, however brilliant, just another way of explaining the typical best-practices you will find in many books of this category. The interview format does make it a great read and nicely condenses the information in a neatly packed question-answer format. It coming from the devil itself gives it some additional credibility :)&lt;/p>
&lt;p>I would also recommend listening to the audiobook version. The two characters, Napoleon Hill and the devil are two different voice actors which really bring the interview to life.&lt;/p>
&lt;p>I&amp;rsquo;d say: &lt;strong>Definitely read it&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/book_reviews/outwitting_the_devil.jpeg" alt="cover">&lt;/p></description></item><item><title>War of Art</title><link>https://svenhofstede.com/war-of-art/</link><pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/war-of-art/</guid><description>&lt;p>&lt;em>Written by Steven Pressfield&lt;/em>&lt;/p>
&lt;p>This books deals with the Resistance creative thinkers feel. Being creative is hard and takes much effort. Being creative is producing something that didn&amp;rsquo;t exist before. Most people stick to consuming instead of producing as consuming is the route of least resistance. Forcing yourself and embracing the uncomfort of producing/being creative will turn someone &lt;em>pro&lt;/em>, as the author describes.&lt;/p>
&lt;p>The author talks about the discipline someone needs to be succesfull in creative endeavours. It may take many failed attempts to get to something worthwhile. The &lt;em>pro&lt;/em> knows this and marches on.&lt;/p>
&lt;p>The author also talks about changing your frame of mind from being myself to being &lt;strong>Myself Inc.&lt;/strong> . Thinking of yourself as a brand or a company abstracts away feelings of self-doubt. You are working for Myself Inc. and trying to make this company great and successfull.&lt;/p>
&lt;p>The &lt;em>pro&lt;/em> is near machine-like in his quest to deliver. It&amp;rsquo;s about just showing up and doing it, every day. None of your initial work will be good but as long as you keep trying, the forces of nature will at some point recognize your defeat of Resistance and help you become a master at your skill.&lt;/p>
&lt;p>While reading I drew parallels with the previous book I read &lt;em>Outwitting the devils&lt;/em> where the devil himself is the force pulling us away from creative thinking. When the devil succeeds these people are moved to the &amp;lsquo;drifters&amp;rsquo; category where people go on through their lives as mainly consumers instead of producers.&lt;/p>
&lt;p>I&amp;rsquo;d say: &lt;strong>Read it&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/book_reviews/war_of_art.jpeg" alt="cover">&lt;/p></description></item><item><title>Be Obsessed or Be Average</title><link>https://svenhofstede.com/be-obsessed-or-be-average/</link><pubDate>Sat, 17 Dec 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/be-obsessed-or-be-average/</guid><description>&lt;p>&lt;em>Written by Grant Cardone&lt;/em>&lt;/p>
&lt;p>I&amp;rsquo;ll start out by saying that I&amp;rsquo;m not a fan of this book. I was warned before reading that it isn&amp;rsquo;t for everyone and I&amp;rsquo;ll have to agree with that statement now. If not for the ease of reading, I don&amp;rsquo;t think I would of completed it.&lt;/p>
&lt;p>The book revolves around the idea of being completely consumed by your goals in life. This means ignoring criticism/negative feedback from anyone, putting in extra hours all the time, being ruthless towards your competitions and squeezing out every last drop of profit from your employees and clients.&lt;/p>
&lt;p>Grant is coming from a sales background. The characteristics listed above could be more present in sales positions compared to say, IT positions. The environment is different, the &amp;lsquo;win-situation&amp;rsquo; is different, your compensation is different.&lt;/p>
&lt;p>The book is a collection of short chapters each highlighting aspects of &lt;em>being obsessed&lt;/em>. However this book also suffers from the typical filler-content that bugs these types of books. In fact, reading through I rarely stopped and thought &amp;lsquo;Hey, that&amp;rsquo;s something new and interesting&amp;rsquo;. There was also a lot of self-promotion and promoting of his other products.&lt;/p>
&lt;p>Obviously the system has been working for him. He&amp;rsquo;s an extremely successful business man, real-estate investor and all-round sales guru. It&amp;rsquo;s therefore hard for me to deny this mentality works. I agree that being committed and certain of your goal is important. You need this to persevere through hard times. But Grant seems to take this to the extreme and I feel like extremes are rarely good.&lt;/p>
&lt;p>I&amp;rsquo;d say: &lt;strong>Skip it&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/book_reviews/be_obsessed.jpeg" alt="cover">&lt;/p></description></item><item><title>What Clean Code taught me</title><link>https://svenhofstede.com/what-clean-code-taught-me/</link><pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/what-clean-code-taught-me/</guid><description>&lt;p>&lt;em>This blog post is work-in-progress while working myself through the book. It will loosely follow the structure of the book.&lt;/em>&lt;/p>
&lt;p>I&amp;rsquo;m currently working on reading through Clean Code by Robert C. Martin. It was clear from the start that the book is full of incredible content and it&amp;rsquo;s well worth the time to study it properly. I&amp;rsquo;m trying to capture the key take-aways I have come across. There is much more to the book then what I&amp;rsquo;m highlighting here but these are things that were somewhat new to me and stuck in my mind as being worth remembering. I would suggest any programmer to have a look at this book in full.&lt;/p>
&lt;p>I&amp;rsquo;m approaching this book from an un-experienced programming in terms of application development. Most of the concepts/patterns are new to me.&lt;/p>
&lt;h2 id="the-art-of-naming">The Art of Naming&lt;/h2>
&lt;p>&lt;em>There are two hard things in computer science: cache invalidation, &lt;strong>naming things&lt;/strong>.&lt;/em>&lt;/p>
&lt;p>The naming of variables and functions is an art in itself. You need to come up with a name that perfectly explains why and how a variable or function is used and what it is. It can&amp;rsquo;t be too long but it shouldn&amp;rsquo;t be too short. Longer is better then shorter if that means the intent is made more clear.&lt;/p>
&lt;h4 id="make-it-searchable">Make it Searchable&lt;/h4>
&lt;p>If possible, make sure the name is searchable. You need to be able to easily jump to a variables. Don&amp;rsquo;t call them &lt;code>x&lt;/code>, &lt;code>counter&lt;/code> or &lt;code>max_number&lt;/code>. If you are using &lt;code>counter&lt;/code> once, you&amp;rsquo;ll probably use it often so finding the right one with your editor find tool is inconvenient. And you don&amp;rsquo;t want the search to bring you to every &lt;code>x&lt;/code> in the text.&lt;/p>
&lt;h4 id="talking-about-variables">Talking about variables&lt;/h4>
&lt;p>Make stuff pronounceable. This helps greatly in talking about the functions and variables with other people. Instead of having to refer to &lt;code>df_incr&lt;/code> we can just &lt;strong>say&lt;/strong> &lt;code>dataframe_incremental&lt;/code>. Yes it might be longer to type but copy-paste and auto-complete are commonplace.&lt;/p>
&lt;h4 id="stick-to-a-word-per-concept">Stick to a word per concept&lt;/h4>
&lt;p>Agree and stick to a single word for a single concept. Are you &lt;em>fetching&lt;/em> or are you &lt;em>getting&lt;/em> a record? Decide and use this going forward when necessary. Don&amp;rsquo;t mix &lt;code>get_record_by_id&lt;/code> with &lt;code>fetch_records&lt;/code>.&lt;/p>
&lt;h2 id="functions">Functions&lt;/h2>
&lt;h4 id="reduce-complexity">Reduce complexity&lt;/h4>
&lt;p>Functions should do one thing.&lt;/p>
&lt;p>For readability you want to limit the number of indent levels to 1 or 2. Anything more then 2 probably means your function is doing &lt;em>too much&lt;/em>. Functions should have &lt;strong>at most&lt;/strong> 3 arguments but ideally you should be aiming for zero if at all possible. Increasing the number of arguments will:&lt;/p>
&lt;ul>
&lt;li>Hard to understand what the function does.&lt;/li>
&lt;li>They pollute the simplicity of the API&lt;/li>
&lt;li>It makes testing more complex&lt;/li>
&lt;/ul>
&lt;p>If you notice your functions really needs multiple argument, consider if it makes sense to replace them by an input object instead.&lt;/p>
&lt;h4 id="avoid-side-effects">Avoid side effects&lt;/h4>
&lt;blockquote>
&lt;p>In computer science, a function or expression is said to have a side effect if it modifies some state or has an observable interaction with calling functions or the outside world.&lt;/p>
&lt;/blockquote>
&lt;p>Side-effects are lies. Your function is doing something that isn&amp;rsquo;t advertised in the name. They also make it difficult to test your function as you need to set-up the &lt;em>outside world&lt;/em> for your function to work. Pure functions are much more reliable as they are guaranteed to return the same value for a given input.&lt;/p>
&lt;h4 id="extract-try-catch-blocks">Extract try-catch blocks.&lt;/h4>
&lt;p>By writing your code in a try block you are mixing error processing with the actual processing.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">try&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#f92672">=&lt;/span> do_something_to_variable(i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> do_something()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> do_another_thing()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">except&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Instead pull this out into a seperate function.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">do_loads_of_things&lt;/span>():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> i &lt;span style="color:#f92672">=&lt;/span> do_something_to_variable(i)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> do_something()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> do_another_thing()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">try&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> do_loads_of_things()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">except&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">raise&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="write-test-write-code-refactor">Write test, write code, refactor&lt;/h4>
&lt;p>It&amp;rsquo;s hard to write clean functions on first pass and people rarely do. There is nothing wrong with writing ugly code that just works and then refactoring it to make it clean. Remember to write tests first so you can safely refactor your code.&lt;/p>
&lt;h2 id="comments">Comments&lt;/h2>
&lt;p>Comments, in general, should be avoided. Try to replace with more expressive function names.&lt;/p>
&lt;p>Don&amp;rsquo;t leave commented code hanging around. If you don&amp;rsquo;t need it, get rid of it. If someone (or even yourself) comes along at a later date they don&amp;rsquo;t know why the code is commented out. They would fear either removing or uncommenting it. Remember you have source control to retrieve old code. Same thing for journal comments, this is dealt with by the source control. No need to track this in the code.&lt;/p>
&lt;p>Add comments near the source of the thing you are commenting. Don&amp;rsquo;t add a comment for a function where you are using the function. Instead comment where the function is defined.&lt;/p>
&lt;h2 id="objects-and-data-structures">Objects and Data Structures&lt;/h2>
&lt;h4 id="the-difference">The difference&lt;/h4>
&lt;p>The difference between objects and data structures lies in their usage. Data structures are meant to provide access to the data directly. Objects hide direct access to data but expose behaviours. They abstract away the retrieval of data.&lt;/p>
&lt;p>You should not be able to navigate through objects by chaining as the underlying implementation should be hidden from sight.&lt;/p>
&lt;h2 id="error-handling">Error Handling&lt;/h2>
&lt;p>Don&amp;rsquo;t forget to write tests for errors that you expect to have happen. Make sure these are tested as well.&lt;/p>
&lt;p>Add context to the error message. When catching the error you are normally aware of why this error is being thrown. Convey this knowledge in the error message so that, when the error occurs, you can easily recall it.&lt;/p>
&lt;p>Wrap third party API exceptions with your own single error. This way you don&amp;rsquo;t need to handle all the possible errors every time you use the API.&lt;/p>
&lt;h2 id="boundaries">Boundaries&lt;/h2>
&lt;p>When dealing with third party API and the boundaries between it and your application, write tests for this boundary. Write tests to learn how the API works. These tests can be simply calling the API and not getting an error. This would be a successfull test. This has two advantages:&lt;/p>
&lt;ul>
&lt;li>It&amp;rsquo;s a great way to learn the API&lt;/li>
&lt;li>Failing tests will alert you of changes in the API (after a new release for example)&lt;/li>
&lt;/ul>
&lt;h4 id="adapter-pattern">Adapter pattern&lt;/h4>
&lt;p>The Person objects has a make_noise() but Dog doesn&amp;rsquo;t. It only has bark(). We implement a DogAdapter which defines the make_noise() to call bark(). All other functions of Dog are routed to the Dog object itself using the &lt;strong>getattr&lt;/strong>. This &amp;lsquo;catch-all&amp;rsquo; sends all remaining function calls to the underlying Dog object.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> dog &lt;span style="color:#f92672">import&lt;/span> Dog
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">Person&lt;/span>(object):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;A representation of a person in 2D Land&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, name):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>name &lt;span style="color:#f92672">=&lt;/span> name
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">make_noise&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#34;hello&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">DogAdapter&lt;/span>(object):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;Adapts the Dog class through encapsulation&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __init__(self, canine):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> self&lt;span style="color:#f92672">.&lt;/span>canine &lt;span style="color:#f92672">=&lt;/span> canine
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">make_noise&lt;/span>(self):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;This is the only method that&amp;#39;s adapted&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> self&lt;span style="color:#f92672">.&lt;/span>canine&lt;span style="color:#f92672">.&lt;/span>bark()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">def&lt;/span> __getattr__(self, attr):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;Everything else is delegated to the object&amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> getattr(self&lt;span style="color:#f92672">.&lt;/span>canine, attr)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">click_creature&lt;/span>(creature):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&amp;#34;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> React to a click by showing the creature&amp;#39;s
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> name and what is says
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#e6db74"> &amp;#34;&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> (creature&lt;span style="color:#f92672">.&lt;/span>name, creature&lt;span style="color:#f92672">.&lt;/span>make_noise())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="unit-tests">Unit Tests&lt;/h2>
&lt;p>Unit tests are as important as the production code itself. They not only make sure your program works as you intended it to but also allows for safe refactoring. Refactoring without tests is a gamble.&lt;/p>
&lt;p>The 5 FIRST principles of testing:&lt;/p>
&lt;ul>
&lt;li>Run &lt;strong>F&lt;/strong>ast&lt;/li>
&lt;li>&lt;strong>I&lt;/strong>ndependant from other tests&lt;/li>
&lt;li>&lt;strong>R&lt;/strong>epeatable&lt;/li>
&lt;li>The outcome is &lt;strong>S&lt;/strong>elf-validating. Outcome is binary.&lt;/li>
&lt;li>Written &lt;strong>T&lt;/strong>imely so before the production code&lt;/li>
&lt;/ul></description></item><item><title>My Reading List</title><link>https://svenhofstede.com/my-reading-list/</link><pubDate>Fri, 02 Dec 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/my-reading-list/</guid><description>&lt;p>My ever-evolving reading list for the coming weeks, months, years :)&lt;/p>
&lt;p>You can click on the [★★★★★]({% post_url 2016-12-02-book-list %}) icons to link to a review I wrote.&lt;/p>
&lt;h3 id="programming">Programming&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Clean Code&lt;/strong> - &lt;em>Robert C. Martin&lt;/em> [★★★★★]({% post_url 2016-12-12-clean-code-summary %})&lt;/li>
&lt;li>&lt;strong>Code Complete&lt;/strong> - &lt;em>Steve McConnell&lt;/em>&lt;/li>
&lt;li>&lt;strong>Head First Design Patterns&lt;/strong> - &lt;em>Eric Freeman, Elisabeth Robson, Bert Bates, Kathy Sierra&lt;/em>&lt;/li>
&lt;li>Structure and Interpretation of Computer Programs - &lt;em>Harold Abelson, Gerald Jay Sussman, Julie Sussman&lt;/em>&lt;/li>
&lt;li>Code: The Hidden Language of Computer Hardware and Software - &lt;em>Charles Petzold&lt;/em>&lt;/li>
&lt;li>Agile Software Development Principles - &lt;em>Robert C. Martin&lt;/em>&lt;/li>
&lt;li>Test-Driven Development - &lt;em>Kent Beck&lt;/em>&lt;/li>
&lt;li>Effective Python - &lt;em>Brett Slatkin&lt;/em>&lt;/li>
&lt;li>Fluent Python - &lt;em>Luciano Ramalho&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="data-science--analytics">Data Science / Analytics&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Learning Spark&lt;/strong> - &lt;em>Holden Karau, Andy Konwinski, Patrick Wendell, Matei Zaharia&lt;/em> ★★★★★&lt;/li>
&lt;li>&lt;strong>Show Me the Numbers&lt;/strong> - &lt;em>Stephen Few&lt;/em> ★★★★★&lt;/li>
&lt;li>&lt;strong>Doing Data Science&lt;/strong> - &lt;em>Cathy O&amp;rsquo;Neil, Rachel Schutt&lt;/em> ★★★★&lt;/li>
&lt;li>&lt;strong>Information Dashboard Design&lt;/strong> - &lt;em>Stephen Few&lt;/em> ★★★★&lt;/li>
&lt;li>&lt;strong>The Art of Data Science&lt;/strong> - &lt;em>Roger D. Peng and Elizabeth Matsui&lt;/em> ★★★&lt;/li>
&lt;li>&lt;strong>Now You See It&lt;/strong> - &lt;em>Stephen Few&lt;/em> ★★★&lt;/li>
&lt;li>The Signal and the Noise - &lt;em>Nate Silver&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="social-skills">Social skills&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>How To Win Friends and Influence People&lt;/strong> - &lt;em>Dale Carnegie&lt;/em> ★★★★★&lt;/li>
&lt;li>The 48 Laws of Power - &lt;em>Robert Greene&lt;/em>&lt;/li>
&lt;li>Leadership and Self-Deception - &lt;em>The Arbinger Institute&lt;/em>&lt;/li>
&lt;li>Influence: The Psychology of Persuasion - &lt;em>Robert B. Cialdini&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="self-development">Self-development&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Outwitting the Devil&lt;/strong> - &lt;em>Napoleon Hill&lt;/em> [★★★★]({% post_url 2016-12-29-outwitting-the-devil %})&lt;/li>
&lt;li>&lt;strong>The Magic of Thinking Big&lt;/strong> - &lt;em>David Schwartz&lt;/em> ★★★★★&lt;/li>
&lt;li>&lt;strong>How to Fail at Almost Everything and Still Win Big&lt;/strong> - &lt;em>Scott Adams&lt;/em> ★★★★★&lt;/li>
&lt;li>&lt;strong>The War of Art&lt;/strong> - &lt;em>Steven Pressfield&lt;/em> [★★★★]({% post_url 2016-12-24-war-of-art %})&lt;/li>
&lt;li>&lt;strong>Man’s Search for Meaning&lt;/strong> - &lt;em>Viktor Frankl&lt;/em> ★★★★&lt;/li>
&lt;li>&lt;strong>The Compound Effect&lt;/strong> - &lt;em>Darren Hardy&lt;/em> ★★★★&lt;/li>
&lt;li>&lt;strong>Be Obsessed or Be Average&lt;/strong> - &lt;em>Grant Cardone&lt;/em> [★★]({% post_url 2016-12-17-be-obsessed %})&lt;/li>
&lt;li>&lt;strong>The Subtle Art of Not Giving a Fuck&lt;/strong> - &lt;em>Mark Manson&lt;/em> ★★★★&lt;/li>
&lt;li>Thinking, Fast and Slow - &lt;em>Daniel Kahneman&lt;/em>&lt;/li>
&lt;li>As a Man Thinketh - &lt;em>James Allen&lt;/em>&lt;/li>
&lt;li>Psycho-Cybernetics - &lt;em>Maxwell Maltz&lt;/em>&lt;/li>
&lt;li>Maximum Achievement - &lt;em>Brian Tracy&lt;/em>&lt;/li>
&lt;li>The 7 Habits of Highly Effective People - &lt;em>Stephen R. Covey&lt;/em>&lt;/li>
&lt;li>Antifragile - &lt;em>Nassim Nicholas Taleb&lt;/em>&lt;/li>
&lt;li>Awaken The Giant Within - &lt;em>Tony Robbins&lt;/em>&lt;/li>
&lt;li>Eat That Frog - &lt;em>Brian Tracy&lt;/em>&lt;/li>
&lt;li>Gödel, Escher, Bach - &lt;em>Douglas Hofstadter&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="stoicism">Stoicism&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>A Guide to the Good Life&lt;/strong> - &lt;em>William B. Irvine&lt;/em> ★★★★★&lt;/li>
&lt;li>&lt;strong>The Daily Stoic&lt;/strong> - &lt;em>Ryan Holiday and Stephen Hanselman&lt;/em> ★★★★★&lt;/li>
&lt;li>&lt;strong>The Obstacle Is The Way&lt;/strong> - &lt;em>Ryan Holiday&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="finance">Finance&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>The 4-hour Work week&lt;/strong> - &lt;em>Tim Ferriss&lt;/em> ★★★★★&lt;/li>
&lt;li>Rich Dad, Poor Dad - &lt;em>Robert Kiyosaki and Sharon Lechter&lt;/em>&lt;/li>
&lt;li>A Random Walk Down Wall Street - &lt;em>Burton Gordon Malkiel&lt;/em>&lt;/li>
&lt;li>The Richest Man In Babylon - &lt;em>George Samuel Clason&lt;/em>&lt;/li>
&lt;li>The Millionaire Fastlane - &lt;em>MJ DeMarco&lt;/em>&lt;/li>
&lt;li>Think &amp;amp; Grow Rich - &lt;em>Napoleon Hill&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="marketing">Marketing&lt;/h3>
&lt;ul>
&lt;li>The E-Myth Revisited - &lt;em>Michael E. Gerber&lt;/em>&lt;/li>
&lt;li>The Personal MBA - &lt;em>Josh Kaufman&lt;/em>&lt;/li>
&lt;/ul>
&lt;h3 id="other">Other&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>The Alchemist&lt;/strong> - &lt;em>Paulo Coelho&lt;/em> [★★★★★]({% post_url 2016-11-26-the-alchemist %})&lt;/li>
&lt;li>&lt;strong>Weapons of Math Destruction&lt;/strong> - &lt;em>Cathy O’Neil&lt;/em> [★★★★]({% post_url 2017-02-19-weapon-of-math-destruction %})&lt;/li>
&lt;li>&lt;strong>Tiny Beautiful Things&lt;/strong> - &lt;em>Cheryl Strayed&lt;/em> ★&lt;/li>
&lt;li>&lt;strong>God&amp;rsquo;s Debris&lt;/strong> - &lt;em>Scott Adams&lt;/em> ★★★★&lt;/li>
&lt;li>The Way of the Superior Man - &lt;em>David Deida&lt;/em>&lt;/li>
&lt;/ul></description></item><item><title>The Alchemist</title><link>https://svenhofstede.com/the-alchemist/</link><pubDate>Sat, 26 Nov 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/the-alchemist/</guid><description>&lt;p>&lt;em>Written by Paulo Coelho&lt;/em>&lt;/p>
&lt;p>This is one of those books that I&amp;rsquo;ll remember for a long time. Paulo is a gifted story-teller.&lt;/p>
&lt;p>The story is a journey. A journey of a young man to find his destiny. It&amp;rsquo;s simple and well-written but what makes this book really great is that it&amp;rsquo;s completely riddled with symbols and metaphors. Practically every character, location and situations that he encounters during his joruney can be related back to something in life. While reading I would constantly be realizing what the author actually means with what he&amp;rsquo;s writing. I don&amp;rsquo;t want to spoil anything so I&amp;rsquo;m not going to give any examples. :)&lt;/p>
&lt;p>I&amp;rsquo;d say: &lt;strong>Definitely read it&lt;/strong>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/book_reviews/the_alchemist.jpeg" alt="cover">&lt;/p></description></item><item><title>Homer's face.. with a Random Forest!</title><link>https://svenhofstede.com/homers-face..-with-a-random-forest/</link><pubDate>Sat, 19 Nov 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/homers-face..-with-a-random-forest/</guid><description>&lt;h1 id="classifying-simpsons-characters-in-images">Classifying Simpsons characters in images&lt;/h1>
&lt;h2 id="dataset">Dataset:&lt;/h2>
&lt;p>Many thanks to &lt;a href="https://github.com/jbencina">jbencina&lt;/a> for making this dataset available. The dataset is available on github &lt;a href="https://github.com/jbencina/simpsons-image-training-dataset">here&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>Collection of 30,693 frames from 65 Simspsons episodes from seasons 3, 4, and 5. Each image is &lt;strong>160x120&lt;/strong> pixels.&lt;/p>
&lt;p>One collection (faces-clean-color) contains isolated frames of Homer (n=1,041), Marge (n=444), Lisa (n=358), and Bart (n=645) totalling (n=2,488). These files are labled as {instance_number}_{character_name}.jpg.&lt;/p>
&lt;p>The second collection (unsorted-color) contains 28,205 unsorted frames which can contain backgrounds, characters, text, etc. The two sets are mutually exclusive. This has been broken up into several archives for upload.&lt;/p>
&lt;/blockquote>
&lt;p>This basically gives us 2488 images to train a Simpsons-classifier-model on. Here we go!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> scipy &lt;span style="color:#f92672">import&lt;/span> misc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> scipy.ndimage &lt;span style="color:#f92672">import&lt;/span> find_objects,label
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> matplotlib.pyplot &lt;span style="color:#66d9ef">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> re
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> os &lt;span style="color:#f92672">import&lt;/span> listdir
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> os.path &lt;span style="color:#f92672">import&lt;/span> isfile, join
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn &lt;span style="color:#f92672">import&lt;/span> metrics
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.ensemble &lt;span style="color:#f92672">import&lt;/span> RandomForestClassifier
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="test-data-split">Test data split&lt;/h3>
&lt;p>I took out 120 images (30 of each character) from the labeled dataset and moved it to a test folder. I&amp;rsquo;ll use this to test my model and see how well it classifies.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>image_path &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;c:/projects/simpsons/faces&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_path_test &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#34;c:/projects/simpsons/faces_test&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_list &lt;span style="color:#f92672">=&lt;/span> [f &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> listdir(image_path) &lt;span style="color:#66d9ef">if&lt;/span> isfile(join(image_path, f))]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_list_test &lt;span style="color:#f92672">=&lt;/span> [f &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> listdir(image_path_test) &lt;span style="color:#66d9ef">if&lt;/span> isfile(join(image_path_test, f))]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>I&amp;rsquo;m using regex to extract the target values from the file names.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>regex_pat &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;_([a-z]+).jpg&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>target_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([re&lt;span style="color:#f92672">.&lt;/span>findall(regex_pat,f)[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>target_array_test &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([re&lt;span style="color:#f92672">.&lt;/span>findall(regex_pat,f)[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_test])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>name_list, name_list_counts &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>unique(target_array, return_counts&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="equal-spread-on-input-data">Equal spread on input data&lt;/h3>
&lt;p>The initial input was skewed towards Homer and Bart. I evened out the training data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>at_most &lt;span style="color:#f92672">=&lt;/span> min(name_list_counts)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_list_by_character &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_list_filtered &lt;span style="color:#f92672">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> name_list:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image_list_by_character&lt;span style="color:#f92672">.&lt;/span>append([x &lt;span style="color:#66d9ef">for&lt;/span> x &lt;span style="color:#f92672">in&lt;/span> image_list &lt;span style="color:#66d9ef">if&lt;/span> x&lt;span style="color:#f92672">.&lt;/span>find(i) &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i &lt;span style="color:#f92672">in&lt;/span> image_list_by_character:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image_list_filtered &lt;span style="color:#f92672">=&lt;/span> image_list_filtered&lt;span style="color:#f92672">+&lt;/span>i[&lt;span style="color:#ae81ff">0&lt;/span>:at_most]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_list_filtered &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(image_list_filtered)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Time to read in the actual images from the new &lt;code>image_list&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>image_array &lt;span style="color:#f92672">=&lt;/span> [misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_filtered]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(image_array)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_test &lt;span style="color:#f92672">=&lt;/span> [misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces_test/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_test]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_test &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(image_array_test)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Need to recalculate the target array as it needs to have less values now.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>target_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([re&lt;span style="color:#f92672">.&lt;/span>findall(regex_pat,f)[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_filtered])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>target_array_test &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([re&lt;span style="color:#f92672">.&lt;/span>findall(regex_pat,f)[&lt;span style="color:#ae81ff">0&lt;/span>] &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_test])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Reshaping the image array to the shape [&lt;em>num_images&lt;/em> , &lt;em>num_cols&lt;/em>]. In this case the number of images is 1312 in our training set. The number of cols is 57600.&lt;/p>
&lt;p>The images are 120 by 160 pixels. Each image therefore has 19200 pixels. Each pixel is represented by 3 RGB values so each pixel has 3 values by itself. So in total, each image has 57600 columns of data.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>image_array &lt;span style="color:#f92672">=&lt;/span> image_array&lt;span style="color:#f92672">.&lt;/span>reshape((&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">57600&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_test &lt;span style="color:#f92672">=&lt;/span> image_array_test&lt;span style="color:#f92672">.&lt;/span>reshape((&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">57600&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_x &lt;span style="color:#f92672">=&lt;/span> image_array[:,&lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_y &lt;span style="color:#f92672">=&lt;/span> target_array
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>rf &lt;span style="color:#f92672">=&lt;/span> RandomForestClassifier(n_estimators&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rf&lt;span style="color:#f92672">.&lt;/span>fit(train_x, train_y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pred &lt;span style="color:#f92672">=&lt;/span> rf&lt;span style="color:#f92672">.&lt;/span>predict(image_array_test[:,&lt;span style="color:#ae81ff">0&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(metrics&lt;span style="color:#f92672">.&lt;/span>classification_report(target_array_test, pred))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code> precision recall f1-score support
bart 0.71 0.80 0.75 30
homer 0.83 0.80 0.81 30
lisa 0.79 0.73 0.76 30
marge 0.93 0.90 0.92 30
avg / total 0.81 0.81 0.81 120
&lt;/code>&lt;/pre>
&lt;h3 id="intermediate-result">Intermediate result&lt;/h3>
&lt;p>By applying standard RandomForest I end up with a f-score of &lt;strong>81%&lt;/strong>.&lt;/p>
&lt;h3 id="next-improvement">Next improvement&lt;/h3>
&lt;p>Use GridSearchCV to find the best configuration for the RandomForest classifier. I was hardcoding the &lt;code>n_estimators&lt;/code> on 100 but I was wondering if this shouldn&amp;rsquo;t be optimized automatically. After googling I found GridSearch. I can use this to optimize the settings for my RandomForest. Let&amp;rsquo;s do that!&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.grid_search &lt;span style="color:#f92672">import&lt;/span> GridSearchCV
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>param_grid &lt;span style="color:#f92672">=&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#e6db74">&amp;#39;n_estimators&amp;#39;&lt;/span>: [&lt;span style="color:#ae81ff">50&lt;/span>, &lt;span style="color:#ae81ff">60&lt;/span>, &lt;span style="color:#ae81ff">70&lt;/span>, &lt;span style="color:#ae81ff">80&lt;/span>, &lt;span style="color:#ae81ff">90&lt;/span>, &lt;span style="color:#ae81ff">100&lt;/span>, &lt;span style="color:#ae81ff">110&lt;/span>, &lt;span style="color:#ae81ff">120&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CV_rfc &lt;span style="color:#f92672">=&lt;/span> GridSearchCV(estimator&lt;span style="color:#f92672">=&lt;/span>rf, param_grid&lt;span style="color:#f92672">=&lt;/span>param_grid, cv&lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CV_rfc&lt;span style="color:#f92672">.&lt;/span>fit(train_x, train_y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(CV_rfc&lt;span style="color:#f92672">.&lt;/span>best_params_)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>{'n_estimators': 80}
&lt;/code>&lt;/pre>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>rf &lt;span style="color:#f92672">=&lt;/span> RandomForestClassifier(n_estimators&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">80&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rf&lt;span style="color:#f92672">.&lt;/span>fit(train_x, train_y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pred &lt;span style="color:#f92672">=&lt;/span> rf&lt;span style="color:#f92672">.&lt;/span>predict(image_array_test[:,&lt;span style="color:#ae81ff">0&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(metrics&lt;span style="color:#f92672">.&lt;/span>classification_report(target_array_test, pred))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code> precision recall f1-score support
bart 0.84 0.87 0.85 30
homer 0.79 0.87 0.83 30
lisa 0.89 0.80 0.84 30
marge 0.93 0.90 0.92 30
avg / total 0.86 0.86 0.86 120
&lt;/code>&lt;/pre>
&lt;h3 id="intermediate-result-1">Intermediate result&lt;/h3>
&lt;p>After changing the number of estimators from 100 to 80, as suggested by the grid search, the accuracy remained almost the same, maybe slightly better.&lt;/p>
&lt;h3 id="next-improvement-1">Next improvement&lt;/h3>
&lt;p>Currently it&amp;rsquo;s using the entire image to classify. However a large portion of the images are useless background information. Especially the pixels on the left and right edge contain background pixels. Let&amp;rsquo;s try snipping off the edges. I&amp;rsquo;ll reduce the image by 20 pixels from each side.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">trim_image&lt;/span>(img):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> img[&lt;span style="color:#ae81ff">20&lt;/span>:&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">20&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>image_array &lt;span style="color:#f92672">=&lt;/span> [misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_filtered]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(image_array)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_test &lt;span style="color:#f92672">=&lt;/span> [misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces_test/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> image_list_test]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_test &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array(image_array_test)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_new &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>empty((&lt;span style="color:#ae81ff">1312&lt;/span>,&lt;span style="color:#ae81ff">120&lt;/span>,&lt;span style="color:#ae81ff">120&lt;/span>,&lt;span style="color:#ae81ff">3&lt;/span>), int)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i,j &lt;span style="color:#f92672">in&lt;/span> enumerate(image_array):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> l,o &lt;span style="color:#f92672">in&lt;/span> enumerate(j):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image_array_new[i][l] &lt;span style="color:#f92672">=&lt;/span> trim_image(o)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>image_array_test_new &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>empty((len(image_array_test),&lt;span style="color:#ae81ff">120&lt;/span>,&lt;span style="color:#ae81ff">120&lt;/span>,&lt;span style="color:#ae81ff">3&lt;/span>), int)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> i,j &lt;span style="color:#f92672">in&lt;/span> enumerate(image_array_test):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> l,o &lt;span style="color:#f92672">in&lt;/span> enumerate(j):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image_array_test_new[i][l] &lt;span style="color:#f92672">=&lt;/span> trim_image(o)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>image_array_new &lt;span style="color:#f92672">=&lt;/span> image_array_new&lt;span style="color:#f92672">.&lt;/span>reshape((&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">120&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">120&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>image_array_test_new &lt;span style="color:#f92672">=&lt;/span> image_array_test_new&lt;span style="color:#f92672">.&lt;/span>reshape((&lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">120&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">120&lt;/span>&lt;span style="color:#f92672">*&lt;/span>&lt;span style="color:#ae81ff">3&lt;/span>))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_x &lt;span style="color:#f92672">=&lt;/span> image_array_new[:,&lt;span style="color:#ae81ff">0&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_y &lt;span style="color:#f92672">=&lt;/span> target_array
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rf &lt;span style="color:#f92672">=&lt;/span> RandomForestClassifier(n_estimators&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">80&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>rf&lt;span style="color:#f92672">.&lt;/span>fit(train_x, train_y)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>pred &lt;span style="color:#f92672">=&lt;/span> rf&lt;span style="color:#f92672">.&lt;/span>predict(image_array_test_new[:,&lt;span style="color:#ae81ff">0&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(metrics&lt;span style="color:#f92672">.&lt;/span>classification_report(target_array_test, pred))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code> precision recall f1-score support
bart 0.81 0.83 0.82 30
homer 0.78 0.83 0.81 30
lisa 0.89 0.80 0.84 30
marge 0.93 0.93 0.93 30
avg / total 0.85 0.85 0.85 120
&lt;/code>&lt;/pre>
&lt;h3 id="result">Result&lt;/h3>
&lt;p>The f-score was slightly better on average but it did not affect the score as much as I expected.&lt;/p>
&lt;h3 id="lesson-learned-1">Lesson learned #1&lt;/h3>
&lt;p>One of my initial models had a strong bias towards predicting Bart and Homer while at the same time Lisa was not getting predicted as often as she should. Turns out the number of input images was skewed. There were many more Homers and Barts then Lisa&amp;rsquo;s.&lt;/p>
&lt;p>I then tried &amp;rsquo;limiting&amp;rsquo; the input images to the minimum number. The character with the least amount of labeled images in the dataset is Lisa who has 338 of them. This means that I might have 1041 images of homer but I&amp;rsquo;m only using 338. The model is being trained on 338 images of Lisa, 338 images of Bart, 338 images of Marge and 338 images of Homer.&lt;/p>
&lt;p>I&amp;rsquo;m not sure if elimating potential training material is best practice but in this case this did cause the model to improve significantly.&lt;/p>
&lt;h3 id="lesson-learned-2">Lesson learned #2&lt;/h3>
&lt;p>Use a package like GridSearch to optimize the settings (for example n_estimators) you provide to the classifier algorithm.&lt;/p>
&lt;h2 id="questions">Questions&lt;/h2>
&lt;ul>
&lt;li>Is it good to reduce your input to prevent introducing a skew in data?&lt;/li>
&lt;li>Grid search suggested changing the &lt;code>n_estimators&lt;/code> to 80. The results were worse of. is this a worthwhile change?&lt;/li>
&lt;li>The results of a RandomForest after different each time. Is this normal?&lt;/li>
&lt;/ul>
&lt;h2 id="final-considerations">Final considerations&lt;/h2>
&lt;p>Another thing I could try to implement is some sort of &lt;strong>face detection&lt;/strong> package. I could use this to pinpoint the pixels. This should would probably improve the model even more then simply trimming off pixels from the edges.&lt;/p>
&lt;p>I tried using OpenCV but I was not able to get the install working (Windows). I&amp;rsquo;m my next face-recognition project I will use OpenCV2.&lt;/p>
&lt;p>I could also manually classify some more images so I have more data to train on. I might try that on a later date.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/simpsons_color_files/simpsons_color_31_0.png" alt="sim_31">&lt;/p>
&lt;h2 id="randomness">Randomness&lt;/h2>
&lt;p>These are the &amp;lsquo;mean&amp;rsquo; images of the characters, based on 20 images.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>bart_images &lt;span style="color:#f92672">=&lt;/span> image_list_by_character[&lt;span style="color:#ae81ff">0&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">20&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>homer_images &lt;span style="color:#f92672">=&lt;/span> image_list_by_character[&lt;span style="color:#ae81ff">1&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">20&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lisa_images &lt;span style="color:#f92672">=&lt;/span> image_list_by_character[&lt;span style="color:#ae81ff">2&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">20&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>marge_images &lt;span style="color:#f92672">=&lt;/span> image_list_by_character[&lt;span style="color:#ae81ff">3&lt;/span>][&lt;span style="color:#ae81ff">0&lt;/span>:&lt;span style="color:#ae81ff">20&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bart_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f, flatten&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> bart_images])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>homer_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f, flatten&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> homer_images])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lisa_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f, flatten&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> lisa_images])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>marge_array &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/&amp;#39;&lt;/span> &lt;span style="color:#f92672">+&lt;/span> f, flatten&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>)&lt;span style="color:#f92672">.&lt;/span>astype(np&lt;span style="color:#f92672">.&lt;/span>uint8) &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> marge_images])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>bart_avg &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>average(bart_array, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>homer_avg &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>average(homer_array, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>lisa_avg &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>average(lisa_array, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>marge_avg &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>average(marge_array, axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>f, axarr &lt;span style="color:#f92672">=&lt;/span> plt&lt;span style="color:#f92672">.&lt;/span>subplots(&lt;span style="color:#ae81ff">2&lt;/span>, &lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>imshow(bart_avg, cmap&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Greys_r&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>set_title(&lt;span style="color:#e6db74">&amp;#39;Bart&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>imshow(homer_avg, cmap&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Greys_r&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>set_title(&lt;span style="color:#e6db74">&amp;#39;Homer&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>imshow(lisa_avg, cmap&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Greys_r&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>set_title(&lt;span style="color:#e6db74">&amp;#39;Lisa&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>imshow(marge_avg, cmap&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;Greys_r&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>axarr[&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>set_title(&lt;span style="color:#e6db74">&amp;#39;Marge&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Fine-tune figure; hide x ticks for top plots and y ticks for right plots&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>setp([a&lt;span style="color:#f92672">.&lt;/span>get_xticklabels() &lt;span style="color:#66d9ef">for&lt;/span> a &lt;span style="color:#f92672">in&lt;/span> axarr[&lt;span style="color:#ae81ff">0&lt;/span>, :]], visible&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>setp([a&lt;span style="color:#f92672">.&lt;/span>get_yticklabels() &lt;span style="color:#66d9ef">for&lt;/span> a &lt;span style="color:#f92672">in&lt;/span> axarr[:, &lt;span style="color:#ae81ff">1&lt;/span>]], visible&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://svenhofstede.com/img/writings/simpsons_color_files/simpsons_color_33_0.png" alt="png">&lt;/p>
&lt;p>This is me while fitting the models.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>imshow(misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces/10_bart.jpg&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://svenhofstede.com/img/writings/simpsons_color_files/simpsons_color_35_0.png" alt="png">&lt;/p>
&lt;p>The model was struggling with this image. It misclassifying it as Marge. Obviously due to the blue background which made it think it was showing marge&amp;rsquo;s hair&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>imshow(misc&lt;span style="color:#f92672">.&lt;/span>imread(&lt;span style="color:#e6db74">&amp;#39;faces_test/1071_homer.jpg&amp;#39;&lt;/span>))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>plt&lt;span style="color:#f92672">.&lt;/span>show()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;img src="https://svenhofstede.com/img/writings/simpsons_color_files/simpsons_color_37_0.png" alt="png">&lt;/p></description></item><item><title>Create radar chart in Tableau</title><link>https://svenhofstede.com/create-radar-chart-in-tableau/</link><pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/create-radar-chart-in-tableau/</guid><description>&lt;!-- raw HTML omitted -->
&lt;h2 id="radar-charts">Radar charts&lt;/h2>
&lt;p>Radar charts is a two dimensional graph that allows for visualizing numerous amount of measures. Normally the number of measures would be at least 4 to give the radar charts it&amp;rsquo;s distinct shape. Many more measures can be displayed, each adding a new &amp;rsquo;leg&amp;rsquo; to graph. The radar chart is sometimes also referred to as a &lt;em>Spider chart&lt;/em>.&lt;/p>
&lt;p>The larger the value, the further the data point is plotted towards the outside of the graph. Larger values are typically considered positive when using a radar chart. The &amp;lsquo;best&amp;rsquo; situation is when all the measures are plotted at the outer edge of the graph.&lt;/p>
&lt;p>It&amp;rsquo;s advised to align and &lt;em>fix the scale&lt;/em> of the measures. You can use one measure with a scale from 0 to 10000 and another measure with a scale between 0 and 100 but only if the relative increases of both measure mean as much. 5000 for the first measure should be similarly as good as 50 for the second measure otherwise the scale does not make sense. It&amp;rsquo;s therefore that radar charts are often used when visualizing scores or percentages as these are usually all based on the same scale (0-100).&lt;/p>
&lt;p>Tableau does not support radar charts out of the box. As with a lot of things in Tableau, you can still imitate the look-and-feel of a radar chart using some nifty work-arounds.&lt;/p>
&lt;p>&lt;strong>Criticism&lt;/strong>&lt;/p>
&lt;p>It&amp;rsquo;s important to note that use of a radar chart is very situational and as in most case a simple bar chart could very well be the better option.&lt;/p>
&lt;h2 id="the-usecase-for-this-demo">The usecase for this demo&lt;/h2>
&lt;p>A teacher wants to visualize the scores of the students using a radar chart. Each student has 8 scores for various classes. The teacher wants to visualize these scores for each student separately.&lt;/p>
&lt;h2 id="tableau">Tableau&lt;/h2>
&lt;h3 id="data-prep">Data prep&lt;/h3>
&lt;p>First we will need to format our data into a certain format. This can be done in Excel, in a SQL query using joins, ..&lt;/p>
&lt;p>What we need is something similar to this:&lt;/p>
&lt;ul>
&lt;li>Student - a column for the unit to with this group metrics apply&lt;/li>
&lt;li>Order - a column to indicate in which order Tableau needs to draw the lines. This could be calculated in Tableau as well with some use of the windowing calculations and &lt;code>index()&lt;/code>.&lt;/li>
&lt;li>Class - the name of a measure&lt;/li>
&lt;li>Value - the value of a measure&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Student&lt;/th>
&lt;th>order&lt;/th>
&lt;th>Class&lt;/th>
&lt;th>Value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>1&lt;/td>
&lt;td>Math&lt;/td>
&lt;td>53&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>2&lt;/td>
&lt;td>English&lt;/td>
&lt;td>55&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>3&lt;/td>
&lt;td>Physics&lt;/td>
&lt;td>74&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>4&lt;/td>
&lt;td>Economics&lt;/td>
&lt;td>83&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>5&lt;/td>
&lt;td>Biology&lt;/td>
&lt;td>30&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>6&lt;/td>
&lt;td>Geography&lt;/td>
&lt;td>81&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>7&lt;/td>
&lt;td>Computer Science&lt;/td>
&lt;td>44&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Tess Roscoe&lt;/td>
&lt;td>8&lt;/td>
&lt;td>Sports&lt;/td>
&lt;td>42&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>1&lt;/td>
&lt;td>Math&lt;/td>
&lt;td>66&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>2&lt;/td>
&lt;td>English&lt;/td>
&lt;td>61&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>3&lt;/td>
&lt;td>Physics&lt;/td>
&lt;td>83&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>4&lt;/td>
&lt;td>Economics&lt;/td>
&lt;td>39&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>5&lt;/td>
&lt;td>Biology&lt;/td>
&lt;td>61&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>6&lt;/td>
&lt;td>Geography&lt;/td>
&lt;td>60&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>7&lt;/td>
&lt;td>Computer Science&lt;/td>
&lt;td>68&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Sherrie Maitland&lt;/td>
&lt;td>8&lt;/td>
&lt;td>Sports&lt;/td>
&lt;td>70&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>Once we have that set up we can move to Tableau.&lt;/p>
&lt;h3 id="determining-angles">Determining angles&lt;/h3>
&lt;p>We are going to be plotting the values around a central point. To decide in what angle compared to this central point we will use &lt;a href="https://en.wikipedia.org/wiki/List_of_trigonometric_identities">trigonometric identities&lt;/a>. These looks something like the following graph:&lt;/p>
&lt;p>&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Unit_circle_angles_color.svg/720px-Unit_circle_angles_color.svg.png" alt="trigonometric identities">&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/confused_cat.PNG" alt="confused_cat">&lt;/p>
&lt;p>Now.. if you are a little confused; I&amp;rsquo;ll explain. It&amp;rsquo;s very simple, I promise.&lt;/p>
&lt;p>Let&amp;rsquo;s say you have 8 measures to visualize. In this case we will need to pick 8 angles on which to plot your data. Wouldn&amp;rsquo;t it be great if could get Tableau to &lt;em>spread these out&lt;/em> for us automatically? Unfortunately this is not the case but rather we need to pick the 8 angles and implement them ourselves.&lt;/p>
&lt;p>Looking at the trigonometric identities we can simply pick 8 lines (vertical, horizontal and/or diagonal) that would nicely spread out the lines. 8 is a convenient number for this. If you have more measures or less measures, you will need to figure out which angles you need to pick to end up with an evenly distributed graph.&lt;/p>
&lt;p>We can choose the 4 vertical and horizontal lines that pass the central point (the ones marked with 0°, 90°, 180° and 270°). Then we can pick the 4 diagonal lines marked with either 45°, 135°, 225° or 315°. These 8 lines will cause the plots to be evenly spread out.&lt;/p>
&lt;p>Once we have decided with lines we need we are only interested in the two calculations indicated for each angle.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/trigo_detail.PNG" alt="trigo_detail">&lt;/p>
&lt;p>The first part indicates what we need to multiply the &lt;strong>Value&lt;/strong> by for the &lt;strong>X-axis&lt;/strong>.&lt;/p>
&lt;p>The second part indicates what we need to multiply the &lt;strong>Value&lt;/strong> by for the &lt;strong>Y-axis&lt;/strong>&lt;/p>
&lt;h3 id="creating-calculated-fields">Creating calculated fields&lt;/h3>
&lt;p>We will create two calculated fields. Given the fields in my example dataset they look like the following, you will probably need to change to values to your use case. You might also need to add or remove entries depending on how many measures you want to visualize. Note that we are doing the multiplication of the &lt;strong>Value&lt;/strong> field here according to the two numbers found in the image. We will use these two calculated fields to determine where te plot out data points.&lt;/p>
&lt;p>&lt;strong>x-axis&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">CASE&lt;/span> [&lt;span style="color:#66d9ef">Class&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Math&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;English&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#f92672">-&lt;/span>sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Physics&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Economics&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> (sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Biology&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Geography&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> (sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Computer Science&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Sports&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span>(&lt;span style="color:#f92672">-&lt;/span>sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">END&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;strong>y-axis&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sql" data-lang="sql">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">CASE&lt;/span> [&lt;span style="color:#66d9ef">Class&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Math&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;English&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> (sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Physics&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Economics&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> (sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Biology&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Geography&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#f92672">-&lt;/span>sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Computer Science&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#f92672">-&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">WHEN&lt;/span> &lt;span style="color:#e6db74">&amp;#34;Sports&amp;#34;&lt;/span> &lt;span style="color:#66d9ef">THEN&lt;/span> [Value] &lt;span style="color:#f92672">*&lt;/span> (&lt;span style="color:#f92672">-&lt;/span>sqrt(&lt;span style="color:#ae81ff">2&lt;/span>)&lt;span style="color:#f92672">/&lt;/span>&lt;span style="color:#ae81ff">2&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">END&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="putting-it-all-together">Putting it all together&lt;/h3>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/radar_full.PNG" alt="radar_full">&lt;/p>
&lt;ol>
&lt;li>Add &lt;strong>x-axis&lt;/strong> field as &lt;strong>AVG&lt;/strong> to Column shelf twice&lt;/li>
&lt;li>Change this to Dual Axis with synchronized axis&lt;/li>
&lt;li>Add &lt;strong>y-axis&lt;/strong> field as &lt;strong>AVG&lt;/strong> to Row shelf twice&lt;/li>
&lt;li>Change this to Dual Axis with synchronized axis&lt;/li>
&lt;li>Change the first pair of x-axis and y-axis to chart type &lt;strong>Polygon&lt;/strong>&lt;/li>
&lt;li>Change the second pair of x-axis and y-axis to chart type &lt;strong>Circle&lt;/strong>&lt;/li>
&lt;li>Add the &lt;strong>Class&lt;/strong> field to the polygon part as &lt;strong>path&lt;/strong>&lt;/li>
&lt;li>Sort this path by the &lt;strong>Order&lt;/strong> field in the dataset&lt;/li>
&lt;li>Add a filter for the &lt;strong>Student&lt;/strong> field&lt;/li>
&lt;li>On the Circles section you can add labels with the actual values&lt;/li>
&lt;li>Optional: Change the color of the Polygon to be transparent and add a border&lt;/li>
&lt;li>Optional: Add coloring of the circles by certain custom groupings.&lt;/li>
&lt;/ol>
&lt;p>After following those steps you should already have a decent result. Of course I would recommend doing some final tweaking. Don&amp;rsquo;t hesitate to reach out if you need some help!&lt;/p>
&lt;p>You can also download the workbook from the embed Tableau Public at the top.&lt;/p></description></item><item><title>Why start blogging</title><link>https://svenhofstede.com/why-start-blogging/</link><pubDate>Mon, 24 Oct 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/why-start-blogging/</guid><description>&lt;h2 id="the-reason">The reason&lt;/h2>
&lt;p>There are a couple of reason why I think it&amp;rsquo;s a great idea to start a blog, especially as an IT professional.&lt;/p>
&lt;h4 id="showcase-what-you-can-do">Showcase what you can do&lt;/h4>
&lt;p>The main reason I&amp;rsquo;m starting to blog is because I think it&amp;rsquo;s a great way to show what you&amp;rsquo;re good at. You can really showcase your expertise by writing in-depth articles on your subject matter. It&amp;rsquo;s freely available 24/7 for anyone interested and it gets your name or brand out there. And hopefully someone else reading it can learn something!&lt;/p>
&lt;h4 id="enjoy-your-own-content">Enjoy your own content&lt;/h4>
&lt;p>The stuff you blog about will be something you are personally interested in or passionate about. This usually leads to better quality output. Something you do with passion, especially if it&amp;rsquo;s voluntary typically means you are going to produce something good. Blogging about side projects give you the freedom to create whatever you want.&lt;/p>
&lt;h4 id="it-makes-you-a-better-writer">It makes you a better writer&lt;/h4>
&lt;p>I&amp;rsquo;m not the best at explaining my ideas and thoughts, neither verbally nor written. Writing a decent blog post is still difficult for me. I need to sit down and really think about structure, content, vocabulary, &amp;hellip; It&amp;rsquo;s that struggle that, over time, will improve my ability as a writer. This is a skill that will help me at work as well as in life in general.&lt;/p>
&lt;h4 id="it-allows-you-to-think">It allows you to think&lt;/h4>
&lt;p>Writing a blog post forces you to really think something through. I spend most of my day speeding through problem solving. A blog post is not a sprint but something you can take your time to perfect. It allows you really process an idea or concept.&lt;/p>
&lt;h4 id="track-your-progress">Track your progress&lt;/h4>
&lt;p>Over time I (hopefully) see my skill increase. A blog will be a nice journal that will stay here forever that nicely keeps track of this progress. It must feel good if you can at some point look back at older blog posts and see clear improvement in skills and writing.&lt;/p>
&lt;h2 id="get-help-getting-started">Get help getting started&lt;/h2>
&lt;p>I was fortunate to come across a guide created by John over at &lt;a href="https://simpleprogrammer.com">simpleprogrammer.com&lt;/a>. He has developed a great &lt;a href="https://simpleprogrammer.com/lp/create-your-blog-1/">step-by-step email guide&lt;/a> that helps you to get started.&lt;/p>
&lt;p>Twice a week, on Monday and Thursday, you will receive an email with simple instructions and tips. John helps you with coming up with content ideas, actually creating the blog itself, getting traffic to your blog and drilling in the most important aspect of proper successfull blogs&amp;hellip; &lt;strong>consistency!&lt;/strong>&lt;/p>
&lt;p>What I enjoyed most about the course is the low barrier of entry. Each step of the way is made easy and takes much less time then you might think. I was actually &lt;em>looking forward&lt;/em> to getting the next mail so I can further develop my blog.&lt;/p></description></item><item><title>Predicting titanic survivors</title><link>https://svenhofstede.com/predicting-titanic-survivors/</link><pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/predicting-titanic-survivors/</guid><description>&lt;h2 id="predicting-titanic-survivors-again">Predicting Titanic Survivors.. again&lt;/h2>
&lt;p>Yes.. I also decided to give the Titanic survival prediction a go. It&amp;rsquo;s probably the go-to starting point for people wanting to learn Machine Learning. Apart from some missing values the dataset itself is pretty clean, the label we are trying to predict &amp;lsquo;makes sense&amp;rsquo;. You can easily reason about what we are going for. If you&amp;rsquo;ve watched the movie you will also have a good idea about what features might be useful ( &lt;em>Woman and children first!&lt;/em> ).&lt;/p>
&lt;h2 id="the-code">The Code&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">%&lt;/span>matplotlib inline
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> pandas &lt;span style="color:#66d9ef">as&lt;/span> pd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> numpy &lt;span style="color:#66d9ef">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> math
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> csv &lt;span style="color:#66d9ef">as&lt;/span> csv
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">from&lt;/span> sklearn.ensemble &lt;span style="color:#f92672">import&lt;/span> RandomForestClassifier
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> re
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">import&lt;/span> matplotlib.pyplot &lt;span style="color:#66d9ef">as&lt;/span> plt
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#39;train.csv&amp;#39;&lt;/span>, header&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="length-of-the-names">Length of the names&lt;/h3>
&lt;p>Tried length of the name. My thinking was: Richer people tend to have longer, more fancy names. But the model did not improve much at all.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># train_df[&amp;#39;Len&amp;#39;] = train_df[&amp;#39;Name&amp;#39;].map(lambda x: len(x))&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Creating a new field called Gender to preserve the Sex field.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_df[&lt;span style="color:#e6db74">&amp;#39;Gender&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df[&lt;span style="color:#e6db74">&amp;#39;Sex&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>map( {&lt;span style="color:#e6db74">&amp;#39;female&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;male&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>} )&lt;span style="color:#f92672">.&lt;/span>astype(int)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="cleaning-up-the-embarked-column">Cleaning up the Embarked column&lt;/h3>
&lt;p>The IF statement just checks if there are any NULL values in the Embarked column. After that it fills in the empty entries (NULL) of the Embarked column with the most occurring value (Mode). Once those gaps are filled in I create a distinct list of the possible values of the Embarked column and store those in &lt;code>Ports&lt;/code>. Then I create a dict to store these distinct values and use the dict to convert the Embarked strings to their corresponding int value in the dict.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> len(train_df&lt;span style="color:#f92672">.&lt;/span>Embarked[ train_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>isnull() ]) &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> train_df&lt;span style="color:#f92672">.&lt;/span>loc[train_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>isnull(),&lt;span style="color:#e6db74">&amp;#39;Embarked&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>dropna()&lt;span style="color:#f92672">.&lt;/span>mode()&lt;span style="color:#f92672">.&lt;/span>values
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Ports &lt;span style="color:#f92672">=&lt;/span> list(enumerate(np&lt;span style="color:#f92672">.&lt;/span>unique(train_df[&lt;span style="color:#e6db74">&amp;#39;Embarked&amp;#39;&lt;/span>]))) &lt;span style="color:#75715e"># determine all values of Embarked,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Ports_dict &lt;span style="color:#f92672">=&lt;/span> {name : i &lt;span style="color:#66d9ef">for&lt;/span> i, name &lt;span style="color:#f92672">in&lt;/span> Ports}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_df&lt;span style="color:#f92672">.&lt;/span>Embarked &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: Ports_dict[x])&lt;span style="color:#f92672">.&lt;/span>astype(int) &lt;span style="color:#75715e"># Convert all Embark strings to int&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="add-title-field">Add Title field&lt;/h3>
&lt;p>It read somewhere online that someone&amp;rsquo;s title can contain interesting information. Not only for improving the model directly but also for &amp;lsquo;forecasting&amp;rsquo; the passengers age. Certain titles are only given to people of a certain age group. &lt;em>Master&lt;/em> for example is given to a young boy. Another example is the difference between Mrs and Ms.&lt;/p>
&lt;p>I&amp;rsquo;m also converting the string value of the title to an integer.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>names_to_keep &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;Miss&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Mr&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Mrs&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Ms&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Master&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">def&lt;/span> &lt;span style="color:#a6e22e">getTitle&lt;/span>(name):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> title &lt;span style="color:#f92672">=&lt;/span> re&lt;span style="color:#f92672">.&lt;/span>search(&lt;span style="color:#e6db74">&amp;#39;, ([A-Za-z]+).&amp;#39;&lt;/span>, name)&lt;span style="color:#f92672">.&lt;/span>group(&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> title &lt;span style="color:#f92672">in&lt;/span> names_to_keep:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> title
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">else&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#e6db74">&amp;#39;Others&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_df[&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Name&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: getTitle(x))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Titles &lt;span style="color:#f92672">=&lt;/span> list(enumerate(np&lt;span style="color:#f92672">.&lt;/span>unique(train_df[&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>])))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Titles_dict &lt;span style="color:#f92672">=&lt;/span> {name : i &lt;span style="color:#66d9ef">for&lt;/span> i, name &lt;span style="color:#f92672">in&lt;/span> Titles}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_df[&lt;span style="color:#e6db74">&amp;#39;TitlesNum&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Titles&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: Titles_dict[x])&lt;span style="color:#f92672">.&lt;/span>astype(int)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip;and now fill in the empty ages with the median of title group&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>mean_ages &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#39;Age&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>mean()&lt;span style="color:#f92672">.&lt;/span>to_dict()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_df&lt;span style="color:#f92672">.&lt;/span>loc[train_df&lt;span style="color:#f92672">.&lt;/span>Age&lt;span style="color:#f92672">.&lt;/span>isnull(),&lt;span style="color:#e6db74">&amp;#39;Age&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Titles&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: mean_ages[x] )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="reading-in-test-data">Reading in test data&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>test_df &lt;span style="color:#f92672">=&lt;/span> pd&lt;span style="color:#f92672">.&lt;/span>read_csv(&lt;span style="color:#e6db74">&amp;#39;test.csv&amp;#39;&lt;/span>, header&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Create Gender column&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_df[&lt;span style="color:#e6db74">&amp;#39;Gender&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> test_df[&lt;span style="color:#e6db74">&amp;#39;Sex&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>map( {&lt;span style="color:#e6db74">&amp;#39;female&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;male&amp;#39;&lt;/span>: &lt;span style="color:#ae81ff">1&lt;/span>} )&lt;span style="color:#f92672">.&lt;/span>astype(int)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Fix Embarked column&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> len(test_df&lt;span style="color:#f92672">.&lt;/span>Embarked[ test_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>isnull() ]) &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> test_df&lt;span style="color:#f92672">.&lt;/span>Embarked[ test_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>isnull() ] &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>dropna()&lt;span style="color:#f92672">.&lt;/span>mode()&lt;span style="color:#f92672">.&lt;/span>values
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Ports &lt;span style="color:#f92672">=&lt;/span> list(enumerate(np&lt;span style="color:#f92672">.&lt;/span>unique(test_df[&lt;span style="color:#e6db74">&amp;#39;Embarked&amp;#39;&lt;/span>]))) &lt;span style="color:#75715e"># determine all values of Embarked,&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Ports_dict &lt;span style="color:#f92672">=&lt;/span> {name : i &lt;span style="color:#66d9ef">for&lt;/span> i, name &lt;span style="color:#f92672">in&lt;/span> Ports}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_df&lt;span style="color:#f92672">.&lt;/span>Embarked &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>Embarked&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: Ports_dict[x])&lt;span style="color:#f92672">.&lt;/span>astype(int)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Add Titles column&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_df[&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>Name&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: getTitle(x))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_df[&lt;span style="color:#e6db74">&amp;#39;TitlesNum&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>Titles&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: Titles_dict[x])&lt;span style="color:#f92672">.&lt;/span>astype(int)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Fix Age by adding median of title group &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mean_ages &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>groupby(&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>)[&lt;span style="color:#e6db74">&amp;#39;Age&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>mean()&lt;span style="color:#f92672">.&lt;/span>to_dict()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">for&lt;/span> key, value &lt;span style="color:#f92672">in&lt;/span> mean_ages&lt;span style="color:#f92672">.&lt;/span>iteritems():
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">if&lt;/span> math&lt;span style="color:#f92672">.&lt;/span>isnan(value):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mean_ages[key] &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>Age&lt;span style="color:#f92672">.&lt;/span>mean()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_df&lt;span style="color:#f92672">.&lt;/span>loc[test_df&lt;span style="color:#f92672">.&lt;/span>Age&lt;span style="color:#f92672">.&lt;/span>isnull(),&lt;span style="color:#e6db74">&amp;#39;Age&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>Titles&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: mean_ages[x] )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># The isnull check each time to make sure the column has values&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> len(test_df&lt;span style="color:#f92672">.&lt;/span>Fare[ test_df&lt;span style="color:#f92672">.&lt;/span>Fare&lt;span style="color:#f92672">.&lt;/span>isnull() ]) &lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#ae81ff">0&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> median_fare &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>zeros(&lt;span style="color:#ae81ff">3&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#66d9ef">for&lt;/span> f &lt;span style="color:#f92672">in&lt;/span> range(&lt;span style="color:#ae81ff">0&lt;/span>,&lt;span style="color:#ae81ff">3&lt;/span>): &lt;span style="color:#75715e"># loop 0 to 2&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> median_fare[f] &lt;span style="color:#f92672">=&lt;/span> test_df[ test_df&lt;span style="color:#f92672">.&lt;/span>Pclass &lt;span style="color:#f92672">==&lt;/span> f&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> ][&lt;span style="color:#e6db74">&amp;#39;Fare&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>dropna()&lt;span style="color:#f92672">.&lt;/span>median()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> test_df&lt;span style="color:#f92672">.&lt;/span>loc[ (test_df&lt;span style="color:#f92672">.&lt;/span>Fare&lt;span style="color:#f92672">.&lt;/span>isnull()) &lt;span style="color:#f92672">&amp;amp;&lt;/span> (test_df&lt;span style="color:#f92672">.&lt;/span>Pclass &lt;span style="color:#f92672">==&lt;/span> f&lt;span style="color:#f92672">+&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span> ), &lt;span style="color:#e6db74">&amp;#39;Fare&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> median_fare[f]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>ids &lt;span style="color:#f92672">=&lt;/span> test_df[&lt;span style="color:#e6db74">&amp;#39;PassengerId&amp;#39;&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>values
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>test_df &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>drop([&lt;span style="color:#e6db74">&amp;#39;Name&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Sex&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Ticket&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Cabin&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;PassengerId&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>], axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>train_df &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>drop([&lt;span style="color:#e6db74">&amp;#39;Name&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Sex&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Ticket&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;Cabin&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;PassengerId&amp;#39;&lt;/span>,&lt;span style="color:#e6db74">&amp;#39;Titles&amp;#39;&lt;/span>], axis&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_data &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>values
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>test_data &lt;span style="color:#f92672">=&lt;/span> test_df&lt;span style="color:#f92672">.&lt;/span>values
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Training...&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>forest &lt;span style="color:#f92672">=&lt;/span> RandomForestClassifier(n_estimators&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">100&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>forest &lt;span style="color:#f92672">=&lt;/span> forest&lt;span style="color:#f92672">.&lt;/span>fit( train_data[&lt;span style="color:#ae81ff">0&lt;/span>::,&lt;span style="color:#ae81ff">1&lt;/span>::], train_data[&lt;span style="color:#ae81ff">0&lt;/span>::,&lt;span style="color:#ae81ff">0&lt;/span>] )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Trained&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Predicting...&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>output &lt;span style="color:#f92672">=&lt;/span> forest&lt;span style="color:#f92672">.&lt;/span>predict(test_data)&lt;span style="color:#f92672">.&lt;/span>astype(int)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Predicted&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>predictions_file &lt;span style="color:#f92672">=&lt;/span> open(&lt;span style="color:#e6db74">&amp;#34;forest_prediction.csv&amp;#34;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;w&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>open_file_object &lt;span style="color:#f92672">=&lt;/span> csv&lt;span style="color:#f92672">.&lt;/span>writer(predictions_file)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>open_file_object&lt;span style="color:#f92672">.&lt;/span>writerow([&lt;span style="color:#e6db74">&amp;#34;PassengerId&amp;#34;&lt;/span>,&lt;span style="color:#e6db74">&amp;#34;Survived&amp;#34;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>open_file_object&lt;span style="color:#f92672">.&lt;/span>writerows(zip(ids, output))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>predictions_file&lt;span style="color:#f92672">.&lt;/span>close()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Done.&amp;#39;&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;pre>&lt;code>Training...
Trained
Predicting...
Predicted
Done.
&lt;/code>&lt;/pre>
&lt;h2 id="the-result">The result&lt;/h2>
&lt;p>After submitting, this predictions came back with a Kaggle score of &lt;strong>0.73206&lt;/strong>. Hurray! Unfortunatly an earlier attempt while strictly following a tutorial had a score of &lt;strong>0.77512&lt;/strong> so I cannot call it an improvement.&lt;/p>
&lt;h1 id="lessons">Lessons&lt;/h1>
&lt;p>At one point I was struggling to update values in a dataframe. After trying out all kinds of solutions myself I eventually looked for some help online. I found a Slack channel and was helped promptly. My issue was the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_df[train_df&lt;span style="color:#f92672">.&lt;/span>Age&lt;span style="color:#f92672">.&lt;/span>isnull()][&lt;span style="color:#e6db74">&amp;#39;Age&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Titles&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: mean_ages[x] )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># I got the following error:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># A value is trying to be set on a copy of a slice from a DataFrame.&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Turns out I was trying to update a copy instead of the original dataframe. Dataframes are sometimes slighly inconsistent when it comes to returning either copies or views. The people in the &lt;a href="https://pythondev.slack.com/messages/data_science/">Slack channel&lt;/a> suggested to the &lt;code>.loc&lt;/code> function on the dataframe to create a view instead of a copy. This is how the code looks after applying this fix.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>train_df&lt;span style="color:#f92672">.&lt;/span>loc[train_df&lt;span style="color:#f92672">.&lt;/span>Age&lt;span style="color:#f92672">.&lt;/span>isnull(),&lt;span style="color:#e6db74">&amp;#39;Age&amp;#39;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> train_df&lt;span style="color:#f92672">.&lt;/span>Titles&lt;span style="color:#f92672">.&lt;/span>map( &lt;span style="color:#66d9ef">lambda&lt;/span> x: mean_ages[x] )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>More information about this can be &lt;a href="http://pandas.pydata.org/pandas-docs/stable/indexing.html">found here&lt;/a>&lt;/p></description></item><item><title>Big O Notation</title><link>https://svenhofstede.com/big-o-notation/</link><pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/big-o-notation/</guid><description>&lt;p>Big-O notation illustrates how a function responds to various inputs. Simply put: How fast will my function run if I change the input from 10 elements to 1000000 elements. Big-O is all about the approximate worst-case performance of doing something. The upper bound is the mathematic limit of the worst output.&lt;/p>
&lt;p>&lt;strong>log&lt;/strong> of 50 = x&lt;/p>
&lt;p>10^x = 50&lt;/p>
&lt;p>To the power of what do I need to raise 10 to end up with 50.&lt;/p>
&lt;h4 id="o1">O(1)&lt;/h4>
&lt;p>Constant. No matter how large or how big the input is, the duration will be the same duration.&lt;/p>
&lt;h4 id="on">O(n)&lt;/h4>
&lt;p>Linear growth. Looping through all the values once.&lt;/p>
&lt;h4 id="olog-n">O(log n)&lt;/h4>
&lt;p>Very small increase but not linear.&lt;/p>
&lt;h4 id="on-log-n">O(n log n)&lt;/h4>
&lt;p>No linear growth as we are multiplying by the log of N. But the log of N will never be big so it&amp;rsquo;s goes up slowly.&lt;/p>
&lt;h4 id="on2">O(n^2)&lt;/h4>
&lt;p>For every entry in the n long list, you need to do n calculations. N squared&lt;/p>
&lt;h4 id="o2n">O(2^n)&lt;/h4>
&lt;p>Grows tremendously fast&lt;/p>
&lt;h4 id="on-1">O(!n)&lt;/h4>
&lt;p>In mathematics, the factorial of a non-negative integer n, denoted by n!, is the product of all positive integers less than or equal to n.&lt;/p>
&lt;ul>
&lt;li>1! = 1&lt;/li>
&lt;li>2! = 2 x 1&lt;/li>
&lt;li>3! = 3 x 2 x 1&lt;/li>
&lt;li>4! = 4 x 3 x 2 x 1&lt;/li>
&lt;/ul>
&lt;p>This gets out of hand extremely quickly.&lt;/p>
&lt;p>&lt;a href="http://bigocheatsheet.com/img/big-o-cheat-sheet-poster.png">Big-o Notation cheatsheet&lt;/a>&lt;/p>
&lt;p>&lt;a href="http://bigocheatsheet.com/?goback=.gde_98713_member_241501229">Lots of extra information and screenshots&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://justin.abrah.ms/computer-science/big-o-notation-explained.html">Good explanation of Big-O&lt;/a>&lt;/p></description></item><item><title>Josh Wills - The Life of a Data Scientist</title><link>https://svenhofstede.com/josh-wills-the-life-of-a-data-scientist/</link><pubDate>Thu, 29 Sep 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/josh-wills-the-life-of-a-data-scientist/</guid><description>&lt;p>&lt;a href="https://www.youtube.com/watch?v=h9vQIPfe2uU" title="Airbnb Tech Talk: Josh Wills - The Life of a Data Scientist">&lt;img src="http://img.youtube.com/vi/h9vQIPfe2uU/0.jpg" alt="IMAGE ALT TEXT">&lt;/a>&lt;/p>
&lt;h3 id="traits-of-data-scientist">Traits of Data scientist&lt;/h3>
&lt;h5 id="being-relentless-in-a-lazy-way">Being relentless in a lazy way&lt;/h5>
&lt;p>Most of your model assumptions are incorrect. He mentions 2/3 of his ideas failed. Being lazy means you DO move on to the next idea and don&amp;rsquo;t stick to it.&lt;/p>
&lt;h5 id="humility">Humility&lt;/h5>
&lt;p>Being at best competent as a statician and scientist. You know enough to talk to expert but you&amp;rsquo;re not an expert but this allows you to learn.&lt;/p>
&lt;h3 id="math-vs-computer-science">Math vs. Computer Science&lt;/h3>
&lt;p>Need to be good at both. Best to atleast study one of these and otherwise study science. Just studying Science (biology, neuroscience, ..) will give you the tools like relentlessness.&lt;/p>
&lt;p>Big Oh notation is important as it gives you the implications of runtimes of programs&lt;/p>
&lt;p>Know your data structures&lt;/p>
&lt;p>Computer science has algorithms and data structures, Data science has random variables and probably modeling&lt;/p>
&lt;p>The difficulty is to find the context when none is provided. Give someone a challenge and mention that they should use a Hashmap. Chances are they won&amp;rsquo;t have a problem implementing it. Give someone a challenge without any context (don&amp;rsquo;t mention hashmap) and now you have a proper indication of a real-world response.&lt;/p>
&lt;p>Statisticians typically don&amp;rsquo;t have the computer science habits. Modular software, testing, code reviews, continuous integration, source control, ..&lt;/p>
&lt;h3 id="kaggle-competitions">Kaggle competitions&lt;/h3>
&lt;p>Kaggle skips a lot of steps. A lot of the work has been done for you. Implementing the machine learning part is typically one of the last steps.&lt;/p>
&lt;h3 id="hadoop--data-science">Hadoop &amp;amp; data science&lt;/h3>
&lt;p>If the traditional infrastructure isn&amp;rsquo;t sufficient, a scientist will find a way to get it to run. It&amp;rsquo;s part of the job.&lt;/p>
&lt;h4 id="unit-of-analysis-problem">Unit of analysis problem&lt;/h4>
&lt;p>Relational databases are bad at:&lt;/p>
&lt;ul>
&lt;li>COUNT DISTINCT - Star models are not optimized for this&lt;/li>
&lt;li>Cursors - If you are using cursors, there is something wrong&lt;/li>
&lt;li>ALTER TABLE_OF_DOOM - That one table in your data warehouse that you cannot touch&lt;/li>
&lt;/ul>
&lt;p>Databases are optimized to analyse transactions. Financial reporting, enterprise resource planning, &amp;hellip;&lt;/p>
&lt;p>Asking questions where all the things you need to know are not in a single table row is typically unperformant in a database.&lt;/p>
&lt;p>Hadoop is simply a file system. You can structure your data as you like. Pull all the fields you need into a single record.&lt;/p>
&lt;h3 id="where-should-you-work-when-starting-out">Where should you work when starting out&lt;/h3>
&lt;p>Start up - Wearing two hats, jack of all trades.&lt;/p>
&lt;p>Close to the money - You can convince people how much money you save or make the company.&lt;/p>
&lt;h3 id="education-and-growth">Education and growth&lt;/h3>
&lt;p>Data scientists usually work in lonely teams, by themselves. No contact and no sharing of data because it&amp;rsquo;s too valuable. No sharing of best practices. Need for communities.&lt;/p>
&lt;h3 id="realtime-ml">Realtime ML&lt;/h3>
&lt;p>Realtime ML is rarely necessary. Pattern in data doesn&amp;rsquo;t change so fast.&lt;/p>
&lt;p>Sometimes writing code to test &amp;lsquo;how something will turn out&amp;rsquo; takes longer than implementing an experiment on live users and seeing the result.&lt;/p>
&lt;h3 id="valuable-stats-content-to-learn">Valuable stats content to learn&lt;/h3>
&lt;ul>
&lt;li>Linaer Regression&lt;/li>
&lt;li>T Test&lt;/li>
&lt;li>Binominal distributions&lt;/li>
&lt;li>Confidence intervals&lt;/li>
&lt;/ul>
&lt;h3 id="josh-wills">Josh Wills&lt;/h3>
&lt;p>Funny and down to earth guy. And I like that he&amp;rsquo;s wearing sandals :)&lt;/p></description></item><item><title>What I think of Tableau</title><link>https://svenhofstede.com/what-i-think-of-tableau/</link><pubDate>Sat, 20 Feb 2016 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/what-i-think-of-tableau/</guid><description>&lt;p>I&amp;rsquo;ve been working with Tableau professionally for the past two years. I create ready-to-use dashboard for end-users who typically consume them via the Tableau Server portal. I feel however that this is not the best use for Tableau and I&amp;rsquo;ll go into details why further on. Let&amp;rsquo;s start with some of the highlights.&lt;/p>
&lt;h2 id="-as-easy-as-excel">+ As easy as Excel&lt;/h2>
&lt;p>Tableau is great. I would advise anyone to go check it out if you are looking for an easy-to-learn, professional package for data exploration/analysis. The core features of Tableau work extremely well and the user experience is great. You can safely hand the program to any experienced computer/excel user and expect them to get started with it.&lt;/p>
&lt;h2 id="-effective-visualization-out-of-the-box">+ Effective visualization out of the box&lt;/h2>
&lt;p>Choosing the right visualization is very important. Explaining the results of your data analysis is about conveying a message, telling a story. It&amp;rsquo;s not supposed to be flashy. Tableau has awesome default graph settings which not only look sleek and clean but also emphasize the message without being distracting. A simple bar chart or line graph usually all you need and Tableau knows this. Very little time is lost formatting and customizing the appearance of the output.&lt;/p>
&lt;h2 id="-speed-of-workflow">+ Speed of workflow&lt;/h2>
&lt;p>Have a new idea? Adding an new view is super convenient. Simply create a new worksheet and drag on the fields. Or even better, duplicate an existing worksheet and modify from there. You find yourself often creating new worksheet to try out different combinations.&lt;/p>
&lt;p>Making is mistake is no problem, the undo button works everytime. This lets you explore freely without worrying of losing your work.&lt;/p>
&lt;h2 id="-tableau-server">+ Tableau Server&lt;/h2>
&lt;p>This is not a crucial product if you a lone data analyst or a small group. The investment is big and only makes sense for certain Tableau environments. It allows for easy sharing and viewing of published Tableau workbooks. The permission system works great.&lt;/p>
&lt;h2 id="--lack-of-developer-focussed-features">- Lack of developer-focussed features&lt;/h2>
&lt;p>The problem with Tableau is typical for any GUI based, end-user focussed product. To be easy to use you need to abstract away a lot of the fine-grained, nitty-gritty controls. This is great if you are a data analyst simply looking to find answers to your questions. You don&amp;rsquo;t want to worry about that, acceptable default settings are fine. However it would be nice to have more control in case you need it.&lt;/p>
&lt;h2 id="--layout-is-a-nightmare">- Layout is a nightmare&lt;/h2>
&lt;p>This probably the biggest pitfall when using Tableau intensively for &amp;lsquo;canned&amp;rsquo; dashboards. If you want your dashboard to look exactly like you would like it to you can expect some major annoyances. Moving elements around on dashboard can be super fidgety. It uses a snap-to-grid style which forces you to structure your dashboard in an unnatural way.&lt;/p>
&lt;p>Responsive design has not yet been implemented properly. The automatic sizing option is actually discouraged when used together with Tableau Server as the server will create a cached version of the output for every requested screen dimension.&lt;/p>
&lt;p>Effectively copying over formatting from one view to another or applying workbook-wide layout/format settings is not possible. You will need to change the font/colors/thickness/number format, .. for each view seperately.&lt;/p>
&lt;p>I know they are working on this and a large overhaul of the system is coming up in a future release so hopefully they make this slightly more bearable.&lt;/p>
&lt;h2 id="--tableau-doesnt-do-lists">- Tableau doesn&amp;rsquo;t do lists&lt;/h2>
&lt;p>Tableau simply doesn&amp;rsquo;t support creating lists, only crosstabs. You can mimic a list using the crosstab but this still has it&amp;rsquo;s limitations. Tableau always expects there to be values in the row section AND the column section.&lt;/p>
&lt;p>Tableau does have an data export feature which in essence is a list of your data but this feature is not customizable. Exporting your data means exporting everything including all the custom calculations you added. This might not sound as bad but I would expect there to be way to customize which columns of the data set you would like to export.&lt;/p>
&lt;h2 id="--strange-data-source-behaviour">- Strange data source behaviour&lt;/h2>
&lt;p>Caching, joining data sets, switching data sources, working with data extracts, .. create a lot of headaches when dealing with data sources, especially in conjunction with Tableau server. This is probably more of an issue once you start connecting to actual databases and try to do complex joins.&lt;/p>
&lt;h2 id="--missing-feature-or-strange-limitations">- Missing feature or strange limitations&lt;/h2>
&lt;p>Finally there are many features that you would expect a product such as Tableau to have by default. A short list below, much more can be found on &lt;!-- raw HTML omitted -->the ideas website&lt;!-- raw HTML omitted -->&lt;/p>
&lt;ul>
&lt;li>Changing/resetting custom color configurations when switching datasource&lt;/li>
&lt;li>No dynamic parameters where value automatically update based on the dataset&lt;/li>
&lt;li>No multi-select prompt using a parameter&lt;/li>
&lt;li>Automatically renaming columns when importing a data source&lt;/li>
&lt;li>Setting font/color/format settings on a workbook level&lt;/li>
&lt;/ul></description></item><item><title>Creating a home gym</title><link>https://svenhofstede.com/creating-a-home-gym/</link><pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/creating-a-home-gym/</guid><description>&lt;h2 id="the-why">The Why&lt;/h2>
&lt;p>I finally decided to invest in my own homegym. I&amp;rsquo;ve been going to a commercial gym for the past two years but lately have been slacking. I prefer to train in the morning or in the evenings. Unfortunately my gym opens at 8AM and in the evenings it&amp;rsquo;s very busy. Like queue-up-for-every-rack/bench busy. Being able to workout whenever I want to seemed pretty convenient so I sat down, did some calculations and came to the conclusion that the costs of buying everything for my home gym won&amp;rsquo;t be so bad.&lt;/p>
&lt;p>Of course you also have the added convenience of not having to drive to the gym. This by itself will save me 30 minutes minimum. Don&amp;rsquo;t forget to take travel expenses into account when calculating the viability of a home gym. I can also play any music that I like&lt;/p>
&lt;h2 id="the-what">The What&lt;/h2>
&lt;p>My workout usually revolve around the 3 big lifts so all I really need is&lt;/p>
&lt;ul>
&lt;li>a barbell&lt;/li>
&lt;li>a bench&lt;/li>
&lt;li>a rack&lt;/li>
&lt;li>some plates&lt;/li>
&lt;/ul>
&lt;p>Note: If your workout calls for various specialized machines then a homegym will probably be too expensive and take up too much space.&lt;/p>
&lt;p>&lt;strong>BUY SECOND HAND!&lt;/strong> There is so much second hand gear to be found on the internet. The trick is to remain patient and wait a while before buying. First scout the various sites and get a feel for the market value of things. You can then quite easily pick out good deals. For me, interesting deals popped up about once a week and therefore bough most if not all of my stuff online.&lt;/p>
&lt;h4 id="rubber-vs-steel">Rubber vs. steel&lt;/h4>
&lt;p>I say go for steel plates. The only exception being for Olympic lifting in which case bumpers are necessary. Steel plates will be cheap, last forever and can be easily sold later on for a decent amount of money. It&amp;rsquo;s also doable to buy rough and beaten-up looking steel plates and giving them some TLC to return them to their former glory. You can find many guides online but it usually consists of&lt;/p>
&lt;ol>
&lt;li>Clean the plates rust/dirt with a cloth and some mineral spirit&lt;/li>
&lt;li>Apply a coat of primer (optional)&lt;/li>
&lt;li>Spray on a hammered paint&lt;/li>
&lt;/ol>
&lt;p>You can even detail the original lettering with some nail polish.&lt;/p>
&lt;h4 id="expensive-barbell">Expensive barbell&lt;/h4>
&lt;p>The general advice is to not be cheap on the barbell. This is your main tool and you will be using it a lot. Having a nice knurling, appropriate flexibility and longevity of the bar will make your training much more pleasurable. If you can find a good barbell second hand, first make sure it&amp;rsquo;s in good condition:&lt;/p>
&lt;ul>
&lt;li>Is the knurling still in good condition and does it provide enough grip? Check the outer sides of the knurling where the bar usually rests on the j-hooks of the rack. This is usually a good indication on the amount of use the barbell has seen.&lt;/li>
&lt;li>Make sure the sleeves of the barbell still turn smoothly without any severe friction.&lt;/li>
&lt;li>Is the barbell perfectly straight?&lt;/li>
&lt;li>Are the ends of the barbell capped or does it contain a bolt like shown below. Bolts using indicate a cheaper barbell.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/barbell_bad.jpg" alt="lesser quality barbell">&lt;/p>
&lt;p>Here&amp;rsquo;s an example of a higher quality barbell which has a cap on the end. This caps makes sure no dirt can enter the inside of the sleeves. High quality barbells rely on bearings for the turning motion and any dirt could prevent these bearings from functioning properly.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/eleiko.PNG" alt="eleiko.PNG">&lt;/p>
&lt;p>All barbells can withstand weights up to a certain, specified limit. If you are just starting out the limits of a cheaper barbell will probably be just fine. If you are a more advanced lifter it might be necessary to check these specifications but if you are an advanced lifter I wouldn&amp;rsquo;t need to be telling you this :)&lt;/p>
&lt;h4 id="the-rack">The Rack&lt;/h4>
&lt;p>Probably the most important piece of equipment you can get. Some things to look out for&lt;/p>
&lt;ul>
&lt;li>Make you the specified weight limit fits your needs&lt;/li>
&lt;li>Test out the hole spacing. If the hole spacing is too big sometimes you will need to unrack/re-rack at a unfortunate position which can be dangerous.&lt;/li>
&lt;li>Does the rack have room for plate storage? If not you might need to buy additional plate storage for convenience.&lt;/li>
&lt;li>Does it have a nice pull up bar?&lt;/li>
&lt;/ul>
&lt;h4 id="the-bench">The Bench&lt;/h4>
&lt;p>It&amp;rsquo;s definitely nice to have an adjustable bench as it opens up some exercises. However, I don&amp;rsquo;t consider it strictly necessary, a flat bench can suffice just fine. I also made sure the bench could handle the weights I was lifting. I obviously don&amp;rsquo;t want the bench to break while I&amp;rsquo;m holding a lot of weight. Also make sure the padding is not too soft and that it&amp;rsquo;s wide enough so it supports your upper back properly.&lt;/p>
&lt;h4 id="floor-material">Floor material&lt;/h4>
&lt;p>There are many tutorials on building lifting platforms online. &lt;a href="HTTPS://www.youtube.com/watch?v=3TzR_mPEo04">This&lt;/a> is a good tutorial by Brandon Campbell, if you can stand the sexual puns.&lt;/p>
&lt;p>A extra tip I can give is the use of rubber playground tiles for sound dampening. These thick but reasonably soft rubber tiles make great deadlift matting/blocks and they cushion the fall perfectly. I had problems with sound and even vibrations using the traditional stall mats and these tiles (which were dirt cheap second hand) fixed the problem entirely.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/speeltuin.jpg" alt="speeltuin.jpg">&lt;/p>
&lt;h4 id="misc">Misc&lt;/h4>
&lt;ul>
&lt;li>
&lt;p>Don&amp;rsquo;t underestimate weight storage. Having to pick up plates of the floor starts to get old real fast. Having the plates stored on the rack is super convenient because you can just slide them off and on to the barbell.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Resistance bands can provide lots of additional exercises and I can highly recommend them. They are awesome for warm-up and stretching/mobility exercises. You can definitely do some tricep or row work but they miss the consistent tension you get with an actual pulley.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="my-gym">My gym&lt;/h2>
&lt;p>Set up the rack&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/gym1.jpg" alt="Gym First photo">&lt;/p>
&lt;p>Got the flooring down. Two layers of MDF and stall mat.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/mat3.jpg" alt="mat 3">&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/mat.jpg" alt="mat close up">&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/mat2.jpg" alt="mat close up 2">&lt;/p>
&lt;p>Final product. Notice the use of the playground rubber tiles instead of the stall mat.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/full2.jpg" alt="Full gym">&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/full.jpg" alt="Full close ">&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/bench.jpg" alt="Bench">&lt;/p>
&lt;p>![Bands](/img/writings/band weights.jpg)&lt;/p></description></item><item><title>Airbnb in New York</title><link>https://svenhofstede.com/airbnb-in-new-york/</link><pubDate>Sun, 20 Sep 2015 00:00:00 +0000</pubDate><guid>https://svenhofstede.com/airbnb-in-new-york/</guid><description>&lt;p>&lt;img src="https://svenhofstede.com/img/writings/airbnb_trans.png" alt="airbnb_trans.png">&lt;/p>
&lt;p>I find Airbnb itself to be an interesting concept. Renting out any left over space you might have in your home seems like a great way of earning some extra cash while at the same time meeting new people.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/cover.jpg" alt="cover.PNG">&lt;/p>
&lt;h2 id="initial-datasets">Initial datasets&lt;/h2>
&lt;p>Airbnb provides datasets containing all the airbnb listings a number of large cities through &lt;a href="http://insideairbnb.com/">insideairbnb&lt;/a>. I thought it would be cool to have a look at some of this data. It triggered my data exploration urge and multiple questions popped into my mind straight away. Let&amp;rsquo;s have a look how Airbnb is like in New York.&lt;/p>
&lt;p>The dataset contains information like Price, Number of Reviews and Number of days available in a year. It also allows for geospatial analysis as we have Borough, Neighborhood and even Latitude and Longitude information.&lt;/p>
&lt;p>I decided to go hunting for some additional data to find possible correlations. I soon bumped into the website &lt;a href="https://nycopendata.socrata.com">nycopendata&lt;/a> which has a bunch of free datasets related to New York. One that caught my eye was &lt;a href="https://nycopendata.socrata.com/Transportation/Subway-Entrances/drex-xx56">Subway Entrances&lt;/a> data. Might there be a correlation between price/ratings and the proximity to a subway entrance?&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/newyork_subway_entrances.jpg" alt="newyork_subway_entrances.PNG">&lt;/p>
&lt;p>I also added the location of the main tourist attractions in New York. It would be interesting to see how the proximity to these affect the price.&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/tourist_attraction_locations2.jpg" alt="tourist_attraction_locations2.PNG">&lt;/p>
&lt;p>I also found datasets containing all the free WifI hotspots and even all public parking lots/garages. I didn&amp;rsquo;t use these dataset in my analysis but you can find them in the Git repo if you&amp;rsquo;re interested.&lt;/p>
&lt;h2 id="data-preparation">Data preparation&lt;/h2>
&lt;p>First I needed to calculate the closest subway entrance. Using R, I came up with the following code. I fully expect this to be unoptimized. It did take a while to go through the 27000+ listings. If you have any suggestion, &lt;a href="http://svenhofstede.github.io/contact/">please let me know!&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>A similar calculations was needed for the closest tourist attractions. Here I also added the name of the attractions itself to the resulting dataset.&lt;/p>
&lt;h2 id="prices">Prices&lt;/h2>
&lt;p>&lt;em>Disclaimer: I have never been to New York so I started with zero prior knowledge of the geo-spatial layout of New York.&lt;/em>&lt;/p>
&lt;p>&lt;img src="https://svenhofstede.com/img/writings/price_count_per_borough.PNG" alt="price_count_per_borough.PNG">&lt;/p>
&lt;p>As expected Manhattan has the highest average price and also the most amount of listings. The majority of the famous attractions in New York (atleast as an unknowing tourist like myself) are located on Manhattan which should bump up the demand and therefore the price.&lt;/p>
&lt;p>Staten Island is the second most expensive borough to stay in. It does however have the least amount of listings.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>The most expensive neighborhood is Tribeca in Manhattan with a hefty average price tag of just over $400 for one night. Not surprising as this is supposed to be one of the most desired neighborhoods in NYC. The list of celebrities who has proporty here is extensive.&lt;/p>
&lt;h2 id="subway-proximity">Subway Proximity&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>The majority of the listings are very close to a subway entrance ( &amp;lt; 400m ) indicated by the blue line. The price of the listings are lower the further away from a subway entrance they are. This can be explained quite easily though. The attractive (more pricey) areas are generally packed with subway entrances. In Manhattan for example you will never be far from the subway whereas outside of Manhattan distances of 400m+ are more common.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="free-wifi">Free WiFi&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;p>Not related to Airbnb but still interesting. NYC seems to provide free WiFi in most parks.&lt;/p></description></item></channel></rss>