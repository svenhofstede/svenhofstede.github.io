---
title: "About"
menu:
  main:
    weight: 20
---

* svenhofstede@gmail.com
* www.svenhofstede.com

## Summary

Senior+ software engineer with over 12 years of experience in both data and software engineering with some DevOps automation knowledge sprinkled on top. I've worked in various roles at  **ASML**, **Nike**, **Johnson & Johnson** and **Ravago**. 

I have experience leading software engineering teams and building products that end users like to use. I enjoy being actively involved in the functional decision making of product design including talking to end users and other stakeholders.

I'm expert level in building resilient and performant data pipelines in Apache (Py)Spark including running it in auto-scaling environments. I've worked with data warehouse tooling like Databricks, Hive and Snowflake for years. I'm very familiar with running and using scheduling tools like for example Airflow. 

I'm comfortable in Linux environments and dealing with software containerization (including Docker and Kubernetes). I'm very experienced in cloud products offered by both Azure and AWS including S3, EKS, EC2, DynamoDB and how to automate setup of this using Terraform.

I'm very comfortable building (web) applications in Python and Java. I've worked on (and lead) multiple production grade applications. I understand the importance of CI/CD, automated testing, backwards compatibility, solid documentation and UX of the product.

I've helped in system design and development of internal data platforms used by data teams globally.

## Experience

### ASML - Data engineer 

*2023 - current*

Helping ASML by building resilient and performant data pipelines using Databricks and PySpark, running on Azure cloud.


### Nike - Lead Software engineer 

*2019 - 2023*

Lead engineer of custom data pipeline-as-a-service solution for Nike
Data & Analytics teams globally.

* Design and implementation of (py)spark framework, built for extensibility
* All data pipelines configured and scheduled via central API (Python,FastAPI)
* Uses Apache Airflow for scheduling of the Spark workloads
* Data is stored on combination of S3/Hive and Databricks. Final datasets in Snowflake
* Everything runs on self-managed, auto-scaling EKS clusters on AWS

### Ravago - Senior Software engineer 

*2017 - 2019*

Development of new features of in-house ERP system based on Spring
Boot

* Investigating bug reports and implementing fixes
* Code reviews, technical analysis and review functional analysis
* Lead administrator of multiple Kubernetes clusters
* Automation of development pipelines using Bamboo and Jenkins

### Johnson & Johnson - Big Data engineer 

*2012 - 2017*

* Set up Data lake environment in Cloudera cluster.
* Develop ingestion mechanism into Data lake (CSV, Databases,SharePoint, REST, ..)
* Develop datamarts using Apache Spark (Scala and Python) and Hive/Impala.

## Education

I completed my bachelor in Computer Science in 2012 at the Thomas More Colleage in Geel, Belgium

## Languages

I'm native speaker in both English and Dutch. 